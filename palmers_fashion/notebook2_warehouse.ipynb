{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4990977 entries, 0 to 4990976\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   sku                      int64         \n",
      " 1   store                    object        \n",
      " 2   date                     datetime64[ns]\n",
      " 3   average_price            float64       \n",
      " 4   average_dicounted_price  float64       \n",
      " 5   sales                    float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(1)\n",
      "memory usage: 228.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sales_data = pd.read_csv('/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/f_sales_v_fashion.csv')\n",
    "sales_data['date'] = pd.to_datetime(sales_data['date'])\n",
    "sales_data['store'] = sales_data['store'].astype(str)\n",
    "sales_data = sales_data.rename(columns={'total_sales':'sales'})\n",
    "sales_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['76', '4134', '4904', '10', '100', '109', '11', '117', '133', '135', '141', '143', '164', '181', '183', '185', '201', '213', '214', '22', '3005', '3202', '4104', '4123', '4129', '42', '45', '46', '4803', '4906', '5', '67', '68', '7', '73', '8', '82', '88', '89', '104', '174', '3208', '37', '63', '91', '96', '202', '21', '90', '95', '121', '144', '147', '173', '4133', '47', '81', '170', '28', '172', '15', '166', '217', '27', '4', '51', '114', '122', '160', '3', '69', '182', '26', '105', '106', '119', '130', '136', '149', '150', '156', '159', '162', '167', '168', '171', '179', '18', '180', '184', '186', '189', '203', '215', '218', '220', '221', '225', '29', '44', '4805', '50', '52', '55', '56', '61', '64', '74', '79', '84', '85', '99', '152', '163', '175', '216', '219', '3245', '57', '3205', '43', '226', '35', '36', '123', '188']\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          100009119000002\n",
      "1          100009134000001\n",
      "2          100009134000003\n",
      "3          100009134000004\n",
      "4          100009134000004\n",
      "                ...       \n",
      "4990972    201999999991001\n",
      "4990973    201999999991001\n",
      "4990974    201999999991001\n",
      "4990975    201999999991001\n",
      "4990976    201999999991001\n",
      "Name: sku, Length: 4990977, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sales_data['sku'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "warehouse_data = pd.read_csv('/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/warehouse_stock_fashion.csv')\n",
    "warehouse_data['valid_to_date'] = warehouse_data['valid_to_date'].replace('2099-12-31', sales_data['date'].max().strftime('%Y-%m-%d'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "list1 = set(warehouse_data[warehouse_data['stock'] > 0 ]['sku'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "list2 = set(sales_data[(sales_data['date'] > '2019-01-01') & (sales_data['sales'] > 0)]['sku'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "list_intersection = list1.intersection(list2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "skus = list(list_intersection)[:100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "sales_data = sales_data[sales_data['sku'].isin(skus)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1356889 entries, 0 to 1356888\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   store            1356889 non-null  object \n",
      " 1   sku              1356889 non-null  int64  \n",
      " 2   valid_from_date  1356889 non-null  object \n",
      " 3   valid_to_date    1356889 non-null  object \n",
      " 4   stock            1356889 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 51.8+ MB\n"
     ]
    }
   ],
   "source": [
    "warehouse_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "warehouse_data = warehouse_data[warehouse_data['sku'].isin(skus)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'2023-12-12'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warehouse_data['valid_to_date'].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "          store              sku valid_from_date valid_to_date  stock  \\\n0           123  100549055000004      2017-04-21    2022-09-03    0.0   \n1            89  100532175000001      2017-04-21    2022-09-03    0.0   \n2            43  100553018000001      2017-04-21    2022-09-03    0.0   \n3           104  100548169000007      2017-04-21    2022-09-03    0.0   \n4            85  100549049000003      2017-04-21    2022-09-03    0.0   \n...         ...              ...             ...           ...    ...   \n17812117     18  100552850000002      2020-05-07    2022-09-03    0.0   \n17812118     99  100653096000013      2020-05-07    2020-08-14    1.0   \n17812119     46  100557049000004      2018-11-17    2022-09-03    0.0   \n17812120      8  100511203000004      2017-04-21    2022-09-03    0.0   \n17812121   3202  100542009000007      2017-04-21    2022-09-03    0.0   \n\n                  item  \n0         100549055000  \n1         100532175000  \n2         100553018000  \n3         100548169000  \n4         100549049000  \n...                ...  \n17812117  100552850000  \n17812118  100653096000  \n17812119  100557049000  \n17812120  100511203000  \n17812121  100542009000  \n\n[17812122 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store</th>\n      <th>sku</th>\n      <th>valid_from_date</th>\n      <th>valid_to_date</th>\n      <th>stock</th>\n      <th>item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>123</td>\n      <td>100549055000004</td>\n      <td>2017-04-21</td>\n      <td>2022-09-03</td>\n      <td>0.0</td>\n      <td>100549055000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>89</td>\n      <td>100532175000001</td>\n      <td>2017-04-21</td>\n      <td>2022-09-03</td>\n      <td>0.0</td>\n      <td>100532175000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>43</td>\n      <td>100553018000001</td>\n      <td>2017-04-21</td>\n      <td>2022-09-03</td>\n      <td>0.0</td>\n      <td>100553018000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104</td>\n      <td>100548169000007</td>\n      <td>2017-04-21</td>\n      <td>2022-09-03</td>\n      <td>0.0</td>\n      <td>100548169000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>85</td>\n      <td>100549049000003</td>\n      <td>2017-04-21</td>\n      <td>2022-09-03</td>\n      <td>0.0</td>\n      <td>100549049000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17812117</th>\n      <td>18</td>\n      <td>100552850000002</td>\n      <td>2020-05-07</td>\n      <td>2022-09-03</td>\n      <td>0.0</td>\n      <td>100552850000</td>\n    </tr>\n    <tr>\n      <th>17812118</th>\n      <td>99</td>\n      <td>100653096000013</td>\n      <td>2020-05-07</td>\n      <td>2020-08-14</td>\n      <td>1.0</td>\n      <td>100653096000</td>\n    </tr>\n    <tr>\n      <th>17812119</th>\n      <td>46</td>\n      <td>100557049000004</td>\n      <td>2018-11-17</td>\n      <td>2022-09-03</td>\n      <td>0.0</td>\n      <td>100557049000</td>\n    </tr>\n    <tr>\n      <th>17812120</th>\n      <td>8</td>\n      <td>100511203000004</td>\n      <td>2017-04-21</td>\n      <td>2022-09-03</td>\n      <td>0.0</td>\n      <td>100511203000</td>\n    </tr>\n    <tr>\n      <th>17812121</th>\n      <td>3202</td>\n      <td>100542009000007</td>\n      <td>2017-04-21</td>\n      <td>2022-09-03</td>\n      <td>0.0</td>\n      <td>100542009000</td>\n    </tr>\n  </tbody>\n</table>\n<p>17812122 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbew_fashion = pd.read_csv('mbew_fashion.csv')\n",
    "mbew_fashion['valid_to_date'] = mbew_fashion['valid_to_date'].replace('2099-12-31', sales_data['date'].max().strftime('%Y-%m-%d'))\n",
    "mbew_fashion['valid_to_date'] = pd.to_datetime(mbew_fashion['valid_to_date'])\n",
    "mbew_fashion['valid_from_date'] = pd.to_datetime(mbew_fashion['valid_from_date'])\n",
    "mbew_fashion['item'] = mbew_fashion['sku'].astype(str).str[:12]\n",
    "mbew_fashion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17812122 entries, 0 to 17812121\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   store            int64         \n",
      " 1   sku              int64         \n",
      " 2   valid_from_date  datetime64[ns]\n",
      " 3   valid_to_date    datetime64[ns]\n",
      " 4   stock            float64       \n",
      " 5   item             object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(2), object(1)\n",
      "memory usage: 815.4+ MB\n"
     ]
    }
   ],
   "source": [
    "mbew_fashion.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "mbew_fashion = mbew_fashion[mbew_fashion['sku'].isin(skus)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/p02my_xx7t193mwjyb2ytt040000gn/T/ipykernel_89960/154987957.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mbew_fashion_no_zero['valid_from_date'] = pd.to_datetime(mbew_fashion_no_zero['valid_from_date'])\n"
     ]
    }
   ],
   "source": [
    "mbew_fashion_no_zero = mbew_fashion[mbew_fashion['stock'] > 0]\n",
    "mbew_fashion_no_zero['valid_from_date'] = pd.to_datetime(mbew_fashion_no_zero['valid_from_date'])\n",
    "dict_of_first_month_date_for_sku = {}\n",
    "i= 0\n",
    "for sku in mbew_fashion_no_zero['sku'].unique():\n",
    "    i+=1\n",
    "    print(str(i) + ' out of ' + str(len(mbew_fashion_no_zero['sku'].unique())))\n",
    "    data_ = mbew_fashion_no_zero[mbew_fashion_no_zero['sku'] == sku]\n",
    "    first_date = data_['valid_from_date'].min()\n",
    "    # put the month in the dict from the first date\n",
    "    dict_of_first_month_date_for_sku[sku] =  first_date.strftime('%m/%y')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([100060075000001])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbew_fashion['sku'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'09/21'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take MM/YY from first date\n",
    "first_date.strftime('%m/%y')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "strong_sku = sales_data.groupby(['sku'])['sales'].sum().sort_values(ascending=False).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for sku in [100630490000001, 100630490000002, 100630490000003, 100630490000004, 100630490000005, 100630490000006, 100630490000007, 100630490000008, 100630490000009, 100630490000010, 100630490000011, 100630490000012, 100630490000013, 100630490000014, 100630490000015, 100630490000016, 100630490000017, 100630490000018, 100630490000019, 100630490000020, 100630490000021,]:\n",
    "#     sku_data = sales_data[sales_data['sku'] == sku].groupby('date')['sales'].sum()\n",
    "#     sku_data = sku_data.reindex(pd.date_range(start=sales_data['date'].min(),\n",
    "#                                                 # today\n",
    "#                                                 end=sales_data['date'].max(),\n",
    "#\n",
    "#                                                 freq='D')).fillna(0)\n",
    "#     sku_warehouse = warehouse_data[warehouse_data['sku'].astype(str) == str(sku)].sort_values(by='valid_from_date')\n",
    "#     sku_warehouse_df_final = pd.DataFrame()\n",
    "#     for row in sku_warehouse.iterrows():\n",
    "#         sku_warehouse_df_final = pd.concat([sku_warehouse_df_final, pd.DataFrame({'date':pd.date_range(start=row[1]['valid_from_date'], end=row[1]['valid_to_date'], freq='D'), 'warehouse stock':row[1]['stock']})])\n",
    "#     sku_warehouse_df_final = sku_warehouse_df_final.set_index('date')\n",
    "#     relevant_sku_stores_stock = mbew_fashion[mbew_fashion['sku'] == sku]\n",
    "#     all_stores_sku_stock_data = {}\n",
    "#     for store in relevant_sku_stores_stock['store'].unique():\n",
    "#         store_sku_data = relevant_sku_stores_stock[relevant_sku_stores_stock['store'] == store]\n",
    "#         one_store_stock_sku_all = pd.DataFrame()\n",
    "#         for row in store_sku_data.iterrows():\n",
    "#             one_store_stock_sku = pd.DataFrame({'date':pd.date_range(start=row[1]['valid_from_date'],\n",
    "#                                                                      end=row[1]['valid_to_date'],\n",
    "#                                                                      freq='D'),\n",
    "#                                                 'store stock':row[1]['stock']})\n",
    "#             one_store_stock_sku_all = pd.concat([one_store_stock_sku_all, one_store_stock_sku])\n",
    "#         one_store_stock_sku_all = one_store_stock_sku_all.set_index('date')\n",
    "#         all_stores_sku_stock_data[store] = one_store_stock_sku_all\n",
    "#         # merge all stores with outer join\n",
    "#     all_stores_final_stock_data = pd.DataFrame()\n",
    "#     for store in all_stores_sku_stock_data.keys():\n",
    "#         relevant_store_data_1 = all_stores_sku_stock_data[store]\n",
    "#         relevant_store_data_1 = relevant_store_data_1.rename(columns={'store stock':'store {}'.format(store) + ' stock'})\n",
    "#         all_stores_final_stock_data = pd.concat([all_stores_final_stock_data, relevant_store_data_1], axis=1, join='outer')\n",
    "#     all_store_sum_stock = all_stores_final_stock_data.sum(axis=1).to_frame().rename(columns={0:'all stores stock'})\n",
    "#     # merge by index\n",
    "#     sku_data = pd.merge(sku_data, sku_warehouse_df_final, left_index=True, right_index=True, how='left').fillna(0)\n",
    "#     sku_data = pd.merge(sku_data, all_store_sum_stock, left_index=True, right_index=True, how='left').fillna(0)\n",
    "#     sku_data_w = sku_data.resample('W').agg({'sales':'sum', 'warehouse stock':'mean', 'all stores stock':'mean'})\n",
    "#     sku_data_w.plot(figsize=(20,4))\n",
    "#     plt.title('sku: ' + str(sku))\n",
    "#\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "sku_warehouse = warehouse_data[warehouse_data['sku'].astype(str) == str(sku)].sort_values(by='valid_from_date')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/p02my_xx7t193mwjyb2ytt040000gn/T/ipykernel_89960/3695414943.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mbew_fashion['sku_store'] = mbew_fashion['sku'].astype(str) + ',' + mbew_fashion['store'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "sales_data['sku_store'] = sales_data['sku'].astype(str) + ',' + sales_data['store'].astype(str)\n",
    "mbew_fashion['sku_store'] = mbew_fashion['sku'].astype(str) + ',' + mbew_fashion['store'].astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store: 10\n",
      "store: 100\n",
      "store: 104\n",
      "store: 105\n",
      "store: 106\n",
      "store: 109\n",
      "store: 11\n",
      "store: 117\n",
      "store: 121\n",
      "store: 122\n",
      "store: 130\n",
      "store: 133\n",
      "store: 136\n",
      "store: 141\n",
      "store: 143\n",
      "store: 144\n",
      "store: 15\n",
      "store: 156\n",
      "store: 160\n",
      "store: 162\n",
      "store: 164\n",
      "store: 166\n",
      "store: 167\n",
      "store: 168\n",
      "store: 170\n",
      "store: 171\n",
      "store: 172\n",
      "store: 173\n",
      "store: 174\n",
      "store: 179\n",
      "store: 180\n",
      "store: 181\n",
      "store: 182\n",
      "store: 183\n",
      "store: 184\n",
      "store: 185\n",
      "store: 186\n",
      "store: 188\n",
      "store: 189\n",
      "store: 201\n",
      "store: 202\n",
      "store: 21\n",
      "store: 213\n",
      "store: 215\n",
      "store: 216\n",
      "store: 217\n",
      "store: 22\n",
      "store: 220\n",
      "store: 221\n",
      "store: 225\n",
      "store: 26\n",
      "store: 27\n",
      "store: 29\n",
      "store: 3\n",
      "store: 3005\n",
      "store: 3202\n",
      "store: 3205\n",
      "store: 3208\n",
      "store: 3245\n",
      "store: 35\n",
      "store: 37\n",
      "store: 4\n",
      "store: 4104\n",
      "store: 4123\n",
      "store: 4129\n",
      "store: 4134\n",
      "store: 42\n",
      "store: 44\n",
      "store: 45\n",
      "store: 46\n",
      "store: 4803\n",
      "store: 4805\n",
      "store: 4904\n",
      "store: 4906\n",
      "store: 5\n",
      "store: 51\n",
      "store: 55\n",
      "store: 56\n",
      "store: 57\n",
      "store: 61\n",
      "store: 63\n",
      "store: 64\n",
      "store: 67\n",
      "store: 68\n",
      "store: 69\n",
      "store: 7\n",
      "store: 73\n",
      "store: 79\n",
      "store: 8\n",
      "store: 81\n",
      "store: 82\n",
      "store: 84\n",
      "store: 85\n",
      "store: 88\n",
      "store: 89\n",
      "store: 90\n",
      "store: 95\n",
      "store: 96\n",
      "store: 99\n",
      "--- 0.916513204574585 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "mbew_fashion = mbew_fashion.sort_values('valid_from_date')\n",
    "\n",
    "for store in sales_data['store'].unique():\n",
    "    print(\"store:\", store)\n",
    "    len_of_store = sales_data[sales_data['store'] == store][\"sku_store\"].nunique()\n",
    "\n",
    "    unique_sku_stores =  sales_data[sales_data['store'] == store][\"sku_store\"].unique()\n",
    "\n",
    "    mbew_fashion['valid_from_date'] = pd.to_datetime(mbew_fashion['valid_from_date'])\n",
    "    mbew_fashion['valid_to_date'] = pd.to_datetime(mbew_fashion['valid_to_date'])\n",
    "    filtered_mbew_fashion = mbew_fashion[mbew_fashion['sku_store'].isin(unique_sku_stores)]\n",
    "\n",
    "    # Function to generate date ranges\n",
    "    def generate_date_ranges(row):\n",
    "        return pd.date_range(row['valid_from_date'], row['valid_to_date'])\n",
    "\n",
    "    # Apply function to create date ranges\n",
    "    df_all_2 = filtered_mbew_fashion.apply(generate_date_ranges, axis=1)\n",
    "\n",
    "    # Create DataFrame with SKU-store and dates\n",
    "    df_all_2 = pd.DataFrame({\n",
    "        'sku_store': np.repeat(filtered_mbew_fashion['sku_store'].values, df_all_2.str.len()),\n",
    "        'date': np.concatenate(df_all_2.values)  # Convert DatetimeIndex to array for concatenation\n",
    "    })\n",
    "    # merge left by ['sku_store', 'date'] and right by ['sku_store', 'valid_to_date']\n",
    "    df_all_2 = pd.merge(df_all_2, filtered_mbew_fashion[['sku_store','valid_from_date', 'stock']], left_on=['sku_store', 'date'], right_on=['sku_store', 'valid_from_date'], how='left')\n",
    "    # ffil stock\n",
    "    df_all_2['stock'] = df_all_2['stock'].ffill()\n",
    "    df_all_2 = df_all_2.drop(columns=['valid_from_date'])\n",
    "    df_all_2 = pd.merge(sales_data, df_all_2, on=[\"sku_store\",\"date\"], how=\"right\")\n",
    "    df_all_2['sku'] = df_all_2['sku_store'].str.split(',').str[0]\n",
    "    df_all_2['store'] = df_all_2['sku_store'].str.split(',').str[1]\n",
    "    df_all_2['item'] = df_all_2['sku'].astype(str).str[:12]\n",
    "    df_all_2['sales'] = df_all_2['sales'].fillna(0)\n",
    "    df_all_2.to_parquet(\"/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/reinforcment_codes/datasets_4/df_all_store_{}.parquet\".format(store))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# generate warehouse data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "sku_unique_in_sales = sales_data['sku'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       store              sku valid_from_date valid_to_date  stock\n",
      "858909  VZ01  100060075000001      2021-08-20    2021-09-13  257.0\n",
      "860675  VZ01  100060075000001      2021-09-14    2021-09-14  160.0\n",
      "860797  VZ01  100060075000001      2021-09-15    2021-09-15  101.0\n",
      "860883  VZ01  100060075000001      2021-09-16    2021-09-16   91.0\n",
      "860984  VZ01  100060075000001      2021-09-17    2021-09-17   83.0\n",
      "861072  VZ01  100060075000001      2021-09-18    2021-09-20   79.0\n",
      "861204  VZ01  100060075000001      2021-09-21    2021-09-21   75.0\n",
      "861349  VZ01  100060075000001      2021-09-22    2021-09-22   73.0\n",
      "861471  VZ01  100060075000001      2021-09-23    2021-09-23   68.0\n",
      "861626  VZ01  100060075000001      2021-09-24    2021-09-24   63.0\n",
      "861740  VZ01  100060075000001      2021-09-25    2021-09-27   60.0\n",
      "861862  VZ01  100060075000001      2021-09-28    2021-09-28   55.0\n",
      "861956  VZ01  100060075000001      2021-09-29    2021-09-29   54.0\n",
      "862089  VZ01  100060075000001      2021-09-30    2021-09-30   51.0\n",
      "862175  VZ01  100060075000001      2021-10-01    2021-10-04   47.0\n",
      "862461  VZ01  100060075000001      2021-10-05    2021-10-05   38.0\n",
      "862567  VZ01  100060075000001      2021-10-06    2021-10-06   35.0\n",
      "862707  VZ01  100060075000001      2021-10-07    2021-10-07   30.0\n",
      "862832  VZ01  100060075000001      2021-10-08    2021-10-08   26.0\n",
      "862963  VZ01  100060075000001      2021-10-09    2021-10-11   23.0\n",
      "863074  VZ01  100060075000001      2021-10-12    2021-10-12   19.0\n",
      "863218  VZ01  100060075000001      2021-10-13    2021-10-13   15.0\n",
      "863366  VZ01  100060075000001      2021-10-14    2021-10-14   12.0\n",
      "863456  VZ01  100060075000001      2021-10-15    2021-10-20   10.0\n",
      "864048  VZ01  100060075000001      2021-10-21    2021-10-21    9.0\n",
      "864119  VZ01  100060075000001      2021-10-22    2021-11-09    8.0\n",
      "865709  VZ01  100060075000001      2021-11-10    2021-11-22    7.0\n",
      "867023  VZ01  100060075000001      2021-11-23    2021-11-23    6.0\n",
      "867186  VZ01  100060075000001      2021-11-24    2021-11-24    4.0\n",
      "867367  VZ01  100060075000001      2021-11-25    2021-11-25    2.0\n",
      "867523  VZ01  100060075000001      2021-11-26    2021-11-26    3.0\n",
      "867594  VZ01  100060075000001      2021-11-27    2021-12-01    2.0\n",
      "868037  VZ01  100060075000001      2021-12-02    2021-12-14    1.0\n",
      "869061  VZ01  100060075000001      2021-12-15    2023-12-12    0.0\n"
     ]
    }
   ],
   "source": [
    "print(warehouse_data[warehouse_data['sku'].isin(skus)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store: VZ01\n",
      "--- 0.009860992431640625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "warehouse_data['valid_from_date'] = pd.to_datetime(warehouse_data['valid_from_date'])\n",
    "warehouse_data['valid_to_date'] = pd.to_datetime(warehouse_data['valid_to_date'])\n",
    "warehouse_data = warehouse_data.sort_values('valid_from_date')\n",
    "warehouse_data['sku_store'] = warehouse_data['sku'].astype(str) + ',' + warehouse_data['store'].astype(str)\n",
    "warehouse_data_sample = warehouse_data[warehouse_data['sku'].isin(sku_unique_in_sales)]\n",
    "for store in ['VZ01']:\n",
    "    print(\"store:\", store)\n",
    "\n",
    "    warehouse_data_sample['valid_from_date'] = pd.to_datetime(warehouse_data_sample['valid_from_date'])\n",
    "    warehouse_data_sample['valid_to_date'] = pd.to_datetime(warehouse_data_sample['valid_to_date'])\n",
    "    filtered_warehouse_data = warehouse_data_sample\n",
    "\n",
    "    # Function to generate date ranges\n",
    "    def generate_date_ranges(row):\n",
    "        return pd.date_range(row['valid_from_date'], row['valid_to_date'])\n",
    "\n",
    "    # Apply function to create date ranges\n",
    "    df_all_2 = filtered_warehouse_data.apply(generate_date_ranges, axis=1)\n",
    "\n",
    "    # Create DataFrame with SKU-store and dates\n",
    "    df_all_2 = pd.DataFrame({\n",
    "        'sku': np.repeat(filtered_warehouse_data['sku'].values, df_all_2.str.len()),\n",
    "        'date': np.concatenate(df_all_2.values)  # Convert DatetimeIndex to array for concatenation\n",
    "    })\n",
    "    df_all_2 = pd.merge(df_all_2, filtered_warehouse_data[['sku','valid_from_date', 'stock']], left_on=['sku', 'date'], right_on=['sku', 'valid_from_date'], how='left')\n",
    "    # ffil stock\n",
    "    df_all_2['stock'] = df_all_2['stock'].ffill()\n",
    "  #  df_all_2 = df_all_2.rename(columns={'stock':'warehouse stock'})\n",
    "    df_all_2 = df_all_2.drop(columns=['valid_from_date'])\n",
    "\n",
    "    df_all_2.to_parquet(\"/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/reinforcment_codes/datasets_4/df_all_store_{}.parquet\".format(store))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                 sku       date  stock\n0    100060075000001 2021-08-20  257.0\n1    100060075000001 2021-08-21  257.0\n2    100060075000001 2021-08-22  257.0\n3    100060075000001 2021-08-23  257.0\n4    100060075000001 2021-08-24  257.0\n..               ...        ...    ...\n840  100060075000001 2023-12-08    0.0\n841  100060075000001 2023-12-09    0.0\n842  100060075000001 2023-12-10    0.0\n843  100060075000001 2023-12-11    0.0\n844  100060075000001 2023-12-12    0.0\n\n[845 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sku</th>\n      <th>date</th>\n      <th>stock</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100060075000001</td>\n      <td>2021-08-20</td>\n      <td>257.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100060075000001</td>\n      <td>2021-08-21</td>\n      <td>257.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100060075000001</td>\n      <td>2021-08-22</td>\n      <td>257.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100060075000001</td>\n      <td>2021-08-23</td>\n      <td>257.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100060075000001</td>\n      <td>2021-08-24</td>\n      <td>257.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>840</th>\n      <td>100060075000001</td>\n      <td>2023-12-08</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>100060075000001</td>\n      <td>2023-12-09</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>842</th>\n      <td>100060075000001</td>\n      <td>2023-12-10</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>843</th>\n      <td>100060075000001</td>\n      <td>2023-12-11</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>844</th>\n      <td>100060075000001</td>\n      <td>2023-12-12</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>845 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "df_all_2.to_parquet(\"df_all_store_{}.parquet\".format(store))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sku_store'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Desktop/Palmers/palmers/venv/local_oran/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/Desktop/Palmers/palmers/venv/local_oran/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Desktop/Palmers/palmers/venv/local_oran/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'sku_store'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf_all_2\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msku_store\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39munique()\n",
      "File \u001B[0;32m~/Desktop/Palmers/palmers/venv/local_oran/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/Desktop/Palmers/palmers/venv/local_oran/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'sku_store'"
     ]
    }
   ],
   "source": [
    "df_all_2['sku_store'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data_sample[warehouse_data_sample['sku'] == '100657013000006']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_sku_stores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mbew_fashion[mbew_fashion['sku_store'] == '100090812000001,100']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2[df_all_2['sku_store'] == '100090812000001,100']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_warehouse_df_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(100630490000005)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
