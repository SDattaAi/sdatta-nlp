{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4990977 entries, 0 to 4990976\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   sku                      int64         \n",
      " 1   store                    object        \n",
      " 2   date                     datetime64[ns]\n",
      " 3   average_price            float64       \n",
      " 4   average_dicounted_price  float64       \n",
      " 5   sales                    float64       \n",
      " 6   item                     object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(2)\n",
      "memory usage: 266.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sales_data = pd.read_csv('/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/f_sales_v_fashion.csv')\n",
    "sales_data['date'] = pd.to_datetime(sales_data['date'])\n",
    "sales_data['item'] = sales_data['sku'].astype(str)\n",
    "sales_data['store'] = sales_data['store'].astype(str)\n",
    "sales_data = sales_data.rename(columns={'total_sales':'sales'})\n",
    "sales_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "sales_data = sales_data[sales_data['sku'].isin([100630105000002, 100259022000005, 100259021000006, 100654238000002, 100259022000002, 100520431000002])]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420565     100259021000006\n",
      "420566     100259021000006\n",
      "420567     100259021000006\n",
      "420568     100259021000006\n",
      "420569     100259021000006\n",
      "                ...       \n",
      "4717656    100654238000002\n",
      "4717657    100654238000002\n",
      "4717658    100654238000002\n",
      "4717659    100654238000002\n",
      "4717660    100654238000002\n",
      "Name: sku, Length: 3266, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sales_data['sku'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "warehouse_data = pd.read_csv('/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/warehouse_stock_fashion.csv')\n",
    "warehouse_data['valid_to_date'] = warehouse_data['valid_to_date'].replace('2099-12-31', sales_data['date'].max().strftime('%Y-%m-%d'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1356889 entries, 0 to 1356888\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   store            1356889 non-null  object \n",
      " 1   sku              1356889 non-null  int64  \n",
      " 2   valid_from_date  1356889 non-null  object \n",
      " 3   valid_to_date    1356889 non-null  object \n",
      " 4   stock            1356889 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 51.8+ MB\n"
     ]
    }
   ],
   "source": [
    "warehouse_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "warehouse_data = warehouse_data[warehouse_data['sku'].isin([100630105000002, 100259022000005, 100259021000006, 100654238000002, 100259022000002, 100520431000002])]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'2023-11-27'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warehouse_data['valid_to_date'].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "          store              sku valid_from_date valid_to_date  stock  \\\n0           123  100549055000004      2017-04-21    2023-11-27    0.0   \n1            89  100532175000001      2017-04-21    2023-11-27    0.0   \n2            43  100553018000001      2017-04-21    2023-11-27    0.0   \n3           104  100548169000007      2017-04-21    2023-11-27    0.0   \n4            85  100549049000003      2017-04-21    2023-11-27    0.0   \n...         ...              ...             ...           ...    ...   \n17812117     18  100552850000002      2020-05-07    2023-11-27    0.0   \n17812118     99  100653096000013      2020-05-07    2020-08-14    1.0   \n17812119     46  100557049000004      2018-11-17    2023-11-27    0.0   \n17812120      8  100511203000004      2017-04-21    2023-11-27    0.0   \n17812121   3202  100542009000007      2017-04-21    2023-11-27    0.0   \n\n                  item  \n0         100549055000  \n1         100532175000  \n2         100553018000  \n3         100548169000  \n4         100549049000  \n...                ...  \n17812117  100552850000  \n17812118  100653096000  \n17812119  100557049000  \n17812120  100511203000  \n17812121  100542009000  \n\n[17812122 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store</th>\n      <th>sku</th>\n      <th>valid_from_date</th>\n      <th>valid_to_date</th>\n      <th>stock</th>\n      <th>item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>123</td>\n      <td>100549055000004</td>\n      <td>2017-04-21</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n      <td>100549055000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>89</td>\n      <td>100532175000001</td>\n      <td>2017-04-21</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n      <td>100532175000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>43</td>\n      <td>100553018000001</td>\n      <td>2017-04-21</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n      <td>100553018000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104</td>\n      <td>100548169000007</td>\n      <td>2017-04-21</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n      <td>100548169000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>85</td>\n      <td>100549049000003</td>\n      <td>2017-04-21</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n      <td>100549049000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17812117</th>\n      <td>18</td>\n      <td>100552850000002</td>\n      <td>2020-05-07</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n      <td>100552850000</td>\n    </tr>\n    <tr>\n      <th>17812118</th>\n      <td>99</td>\n      <td>100653096000013</td>\n      <td>2020-05-07</td>\n      <td>2020-08-14</td>\n      <td>1.0</td>\n      <td>100653096000</td>\n    </tr>\n    <tr>\n      <th>17812119</th>\n      <td>46</td>\n      <td>100557049000004</td>\n      <td>2018-11-17</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n      <td>100557049000</td>\n    </tr>\n    <tr>\n      <th>17812120</th>\n      <td>8</td>\n      <td>100511203000004</td>\n      <td>2017-04-21</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n      <td>100511203000</td>\n    </tr>\n    <tr>\n      <th>17812121</th>\n      <td>3202</td>\n      <td>100542009000007</td>\n      <td>2017-04-21</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n      <td>100542009000</td>\n    </tr>\n  </tbody>\n</table>\n<p>17812122 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbew_fashion = pd.read_csv('mbew_fashion.csv')\n",
    "mbew_fashion['valid_to_date'] = mbew_fashion['valid_to_date'].replace('2099-12-31', sales_data['date'].max().strftime('%Y-%m-%d'))\n",
    "mbew_fashion['valid_to_date'] = pd.to_datetime(mbew_fashion['valid_to_date'])\n",
    "mbew_fashion['valid_from_date'] = pd.to_datetime(mbew_fashion['valid_from_date'])\n",
    "mbew_fashion['item'] = mbew_fashion['sku'].astype(str).str[:12]\n",
    "mbew_fashion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17812122 entries, 0 to 17812121\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   store            int64         \n",
      " 1   sku              int64         \n",
      " 2   valid_from_date  datetime64[ns]\n",
      " 3   valid_to_date    datetime64[ns]\n",
      " 4   stock            float64       \n",
      " 5   item             object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(2), object(1)\n",
      "memory usage: 815.4+ MB\n"
     ]
    }
   ],
   "source": [
    "mbew_fashion.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "mbew_fashion = mbew_fashion[mbew_fashion['sku'].isin([100630105000002, 100259022000005, 100259021000006, 100654238000002, 100259022000002, 100520431000002])]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 4\n",
      "2 out of 4\n",
      "3 out of 4\n",
      "4 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/p02my_xx7t193mwjyb2ytt040000gn/T/ipykernel_98535/154987957.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mbew_fashion_no_zero['valid_from_date'] = pd.to_datetime(mbew_fashion_no_zero['valid_from_date'])\n"
     ]
    }
   ],
   "source": [
    "mbew_fashion_no_zero = mbew_fashion[mbew_fashion['stock'] > 0]\n",
    "mbew_fashion_no_zero['valid_from_date'] = pd.to_datetime(mbew_fashion_no_zero['valid_from_date'])\n",
    "dict_of_first_month_date_for_sku = {}\n",
    "i= 0\n",
    "for sku in mbew_fashion_no_zero['sku'].unique():\n",
    "    i+=1\n",
    "    print(str(i) + ' out of ' + str(len(mbew_fashion_no_zero['sku'].unique())))\n",
    "    data_ = mbew_fashion_no_zero[mbew_fashion_no_zero['sku'] == sku]\n",
    "    first_date = data_['valid_from_date'].min()\n",
    "    # put the month in the dict from the first date\n",
    "    dict_of_first_month_date_for_sku[sku] =  first_date.strftime('%m/%y')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([100259021000006, 100630105000002, 100654238000002, 100259022000002,\n       100259022000005, 100520431000002])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbew_fashion['sku'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "'10/17'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take MM/YY from first date\n",
    "first_date.strftime('%m/%y')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strong_sku = sales_data.groupby(['sku'])['sales'].sum().sort_values(ascending=False).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for sku in [100630490000001, 100630490000002, 100630490000003, 100630490000004, 100630490000005, 100630490000006, 100630490000007, 100630490000008, 100630490000009, 100630490000010, 100630490000011, 100630490000012, 100630490000013, 100630490000014, 100630490000015, 100630490000016, 100630490000017, 100630490000018, 100630490000019, 100630490000020, 100630490000021,]:\n",
    "    sku_data = sales_data[sales_data['sku'] == sku].groupby('date')['sales'].sum()\n",
    "    sku_data = sku_data.reindex(pd.date_range(start=sales_data['date'].min(),\n",
    "                                                # today\n",
    "                                                end=sales_data['date'].max(),\n",
    "\n",
    "                                                freq='D')).fillna(0)\n",
    "    sku_warehouse = warehouse_data[warehouse_data['sku'].astype(str) == str(sku)].sort_values(by='valid_from_date')\n",
    "    sku_warehouse_df_final = pd.DataFrame()\n",
    "    for row in sku_warehouse.iterrows():\n",
    "        sku_warehouse_df_final = pd.concat([sku_warehouse_df_final, pd.DataFrame({'date':pd.date_range(start=row[1]['valid_from_date'], end=row[1]['valid_to_date'], freq='D'), 'warehouse stock':row[1]['stock']})])\n",
    "    sku_warehouse_df_final = sku_warehouse_df_final.set_index('date')\n",
    "    relevant_sku_stores_stock = mbew_fashion[mbew_fashion['sku'] == sku]\n",
    "    all_stores_sku_stock_data = {}\n",
    "    for store in relevant_sku_stores_stock['store'].unique():\n",
    "        store_sku_data = relevant_sku_stores_stock[relevant_sku_stores_stock['store'] == store]\n",
    "        one_store_stock_sku_all = pd.DataFrame()\n",
    "        for row in store_sku_data.iterrows():\n",
    "            one_store_stock_sku = pd.DataFrame({'date':pd.date_range(start=row[1]['valid_from_date'],\n",
    "                                                                     end=row[1]['valid_to_date'],\n",
    "                                                                     freq='D'),\n",
    "                                                'store stock':row[1]['stock']})\n",
    "            one_store_stock_sku_all = pd.concat([one_store_stock_sku_all, one_store_stock_sku])\n",
    "        one_store_stock_sku_all = one_store_stock_sku_all.set_index('date')\n",
    "        all_stores_sku_stock_data[store] = one_store_stock_sku_all\n",
    "        # merge all stores with outer join\n",
    "    all_stores_final_stock_data = pd.DataFrame()\n",
    "    for store in all_stores_sku_stock_data.keys():\n",
    "        relevant_store_data_1 = all_stores_sku_stock_data[store]\n",
    "        relevant_store_data_1 = relevant_store_data_1.rename(columns={'store stock':'store {}'.format(store) + ' stock'})\n",
    "        all_stores_final_stock_data = pd.concat([all_stores_final_stock_data, relevant_store_data_1], axis=1, join='outer')\n",
    "    all_store_sum_stock = all_stores_final_stock_data.sum(axis=1).to_frame().rename(columns={0:'all stores stock'})\n",
    "    # merge by index\n",
    "    sku_data = pd.merge(sku_data, sku_warehouse_df_final, left_index=True, right_index=True, how='left').fillna(0)\n",
    "    sku_data = pd.merge(sku_data, all_store_sum_stock, left_index=True, right_index=True, how='left').fillna(0)\n",
    "    sku_data_w = sku_data.resample('W').agg({'sales':'sum', 'warehouse stock':'mean', 'all stores stock':'mean'})\n",
    "    sku_data_w.plot(figsize=(20,4))\n",
    "    plt.title('sku: ' + str(sku))\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "sku_warehouse = warehouse_data[warehouse_data['sku'].astype(str) == str(sku)].sort_values(by='valid_from_date')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/p02my_xx7t193mwjyb2ytt040000gn/T/ipykernel_98535/3695414943.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mbew_fashion['sku_store'] = mbew_fashion['sku'].astype(str) + ',' + mbew_fashion['store'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "sales_data['sku_store'] = sales_data['sku'].astype(str) + ',' + sales_data['store'].astype(str)\n",
    "mbew_fashion['sku_store'] = mbew_fashion['sku'].astype(str) + ',' + mbew_fashion['store'].astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store: 10\n",
      "store: 100\n",
      "store: 104\n",
      "store: 106\n",
      "store: 109\n",
      "store: 11\n",
      "store: 130\n",
      "store: 133\n",
      "store: 135\n",
      "store: 136\n",
      "store: 141\n",
      "store: 143\n",
      "store: 144\n",
      "store: 162\n",
      "store: 164\n",
      "store: 173\n",
      "store: 179\n",
      "store: 183\n",
      "store: 188\n",
      "store: 189\n",
      "store: 202\n",
      "store: 217\n",
      "store: 219\n",
      "store: 27\n",
      "store: 29\n",
      "store: 3\n",
      "store: 37\n",
      "store: 42\n",
      "store: 44\n",
      "store: 46\n",
      "store: 5\n",
      "store: 55\n",
      "store: 57\n",
      "store: 63\n",
      "store: 64\n",
      "store: 68\n",
      "store: 69\n",
      "store: 7\n",
      "store: 73\n",
      "store: 76\n",
      "store: 79\n",
      "store: 8\n",
      "store: 82\n",
      "store: 88\n",
      "store: 89\n",
      "store: 90\n",
      "store: 95\n",
      "store: 96\n",
      "store: 99\n",
      "store: 172\n",
      "store: 105\n",
      "store: 114\n",
      "store: 117\n",
      "store: 119\n",
      "store: 121\n",
      "store: 122\n",
      "store: 123\n",
      "store: 147\n",
      "store: 149\n",
      "store: 15\n",
      "store: 150\n",
      "store: 152\n",
      "store: 156\n",
      "store: 159\n",
      "store: 160\n",
      "store: 163\n",
      "store: 166\n",
      "store: 167\n",
      "store: 168\n",
      "store: 170\n",
      "store: 171\n",
      "store: 174\n",
      "store: 175\n",
      "store: 18\n",
      "store: 180\n",
      "store: 181\n",
      "store: 182\n",
      "store: 184\n",
      "store: 185\n",
      "store: 186\n",
      "store: 201\n",
      "store: 203\n",
      "store: 21\n",
      "store: 213\n",
      "store: 214\n",
      "store: 215\n",
      "store: 216\n",
      "store: 218\n",
      "store: 22\n",
      "store: 220\n",
      "store: 221\n",
      "store: 225\n",
      "store: 26\n",
      "store: 28\n",
      "store: 3005\n",
      "store: 3202\n",
      "store: 3205\n",
      "store: 3208\n",
      "store: 3245\n",
      "store: 35\n",
      "store: 36\n",
      "store: 4\n",
      "store: 4104\n",
      "store: 4123\n",
      "store: 4129\n",
      "store: 4133\n",
      "store: 4134\n",
      "store: 43\n",
      "store: 45\n",
      "store: 47\n",
      "store: 4803\n",
      "store: 4805\n",
      "store: 4904\n",
      "store: 4906\n",
      "store: 50\n",
      "store: 51\n",
      "store: 52\n",
      "store: 56\n",
      "store: 61\n",
      "store: 67\n",
      "store: 74\n",
      "store: 81\n",
      "store: 84\n",
      "store: 85\n",
      "store: 91\n",
      "store: 226\n",
      "--- 2.736495018005371 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "mbew_fashion = mbew_fashion.sort_values('valid_from_date')\n",
    "\n",
    "for store in sales_data['store'].unique():\n",
    "    print(\"store:\", store)\n",
    "    len_of_store = sales_data[sales_data['store'] == store][\"sku_store\"].nunique()\n",
    "\n",
    "    unique_sku_stores =  sales_data[sales_data['store'] == store][\"sku_store\"].unique()\n",
    "\n",
    "    mbew_fashion['valid_from_date'] = pd.to_datetime(mbew_fashion['valid_from_date'])\n",
    "    mbew_fashion['valid_to_date'] = pd.to_datetime(mbew_fashion['valid_to_date'])\n",
    "    filtered_mbew_fashion = mbew_fashion[mbew_fashion['sku_store'].isin(unique_sku_stores)]\n",
    "\n",
    "    # Function to generate date ranges\n",
    "    def generate_date_ranges(row):\n",
    "        return pd.date_range(row['valid_from_date'], row['valid_to_date'])\n",
    "\n",
    "    # Apply function to create date ranges\n",
    "    df_all_2 = filtered_mbew_fashion.apply(generate_date_ranges, axis=1)\n",
    "\n",
    "    # Create DataFrame with SKU-store and dates\n",
    "    df_all_2 = pd.DataFrame({\n",
    "        'sku_store': np.repeat(filtered_mbew_fashion['sku_store'].values, df_all_2.str.len()),\n",
    "        'date': np.concatenate(df_all_2.values)  # Convert DatetimeIndex to array for concatenation\n",
    "    })\n",
    "    # merge left by ['sku_store', 'date'] and right by ['sku_store', 'valid_to_date']\n",
    "    df_all_2 = pd.merge(df_all_2, filtered_mbew_fashion[['sku_store','valid_from_date', 'stock']], left_on=['sku_store', 'date'], right_on=['sku_store', 'valid_from_date'], how='left')\n",
    "    # ffil stock\n",
    "    df_all_2['stock'] = df_all_2['stock'].ffill()\n",
    "    df_all_2 = df_all_2.drop(columns=['valid_from_date'])\n",
    "    df_all_2 = pd.merge(sales_data, df_all_2, on=[\"sku_store\",\"date\"], how=\"right\")\n",
    "    df_all_2['sku'] = df_all_2['sku_store'].str.split(',').str[0]\n",
    "    df_all_2['store'] = df_all_2['sku_store'].str.split(',').str[1]\n",
    "    df_all_2['item'] = df_all_2['sku'].astype(str).str[:12]\n",
    "    df_all_2['sales'] = df_all_2['sales'].fillna(0)\n",
    "    df_all_2.to_parquet(\"/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/reinforcment_codes/datasets_4/df_all_store_{}.parquet\".format(store))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sku store       date  average_price  average_dicounted_price  \\\n",
      "0    100654238000002   226 2022-03-02            NaN                      NaN   \n",
      "1    100654238000002   226 2022-03-03            NaN                      NaN   \n",
      "2    100654238000002   226 2022-03-04            NaN                      NaN   \n",
      "3    100654238000002   226 2022-03-05            NaN                      NaN   \n",
      "4    100654238000002   226 2022-03-06            NaN                      NaN   \n",
      "..               ...   ...        ...            ...                      ...   \n",
      "631  100654238000002   226 2023-11-23            NaN                      NaN   \n",
      "632  100654238000002   226 2023-11-24            NaN                      NaN   \n",
      "633  100654238000002   226 2023-11-25            NaN                      NaN   \n",
      "634  100654238000002   226 2023-11-26            NaN                      NaN   \n",
      "635  100654238000002   226 2023-11-27            NaN                      NaN   \n",
      "\n",
      "     sales          item            sku_store  stock  \n",
      "0      0.0  100654238000  100654238000002,226    0.0  \n",
      "1      0.0  100654238000  100654238000002,226    0.0  \n",
      "2      0.0  100654238000  100654238000002,226    0.0  \n",
      "3      0.0  100654238000  100654238000002,226    6.0  \n",
      "4      0.0  100654238000  100654238000002,226    6.0  \n",
      "..     ...           ...                  ...    ...  \n",
      "631    0.0  100654238000  100654238000002,226    0.0  \n",
      "632    0.0  100654238000  100654238000002,226    0.0  \n",
      "633    0.0  100654238000  100654238000002,226    0.0  \n",
      "634    0.0  100654238000  100654238000002,226    0.0  \n",
      "635    0.0  100654238000  100654238000002,226    0.0  \n",
      "\n",
      "[636 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_all_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# generate warehouse data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "sku_unique_in_sales = sales_data['sku'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       store              sku valid_from_date valid_to_date   stock\n",
      "3987    VZ01  100259021000006      2021-01-30    2021-07-02  1128.0\n",
      "4045    VZ01  100259021000006      2021-07-03    2021-07-05  1118.0\n",
      "4147    VZ01  100259021000006      2021-07-06    2021-07-06  1117.0\n",
      "4253    VZ01  100259021000006      2021-07-07    2021-07-07  1112.0\n",
      "4307    VZ01  100259021000006      2021-07-08    2021-07-26  1103.0\n",
      "...      ...              ...             ...           ...     ...\n",
      "975288  VZ01  100520431000002      2020-01-24    2020-01-28     0.0\n",
      "975758  VZ01  100520431000002      2020-01-29    2020-01-30     1.0\n",
      "976002  VZ01  100520431000002      2020-01-31    2020-02-01     8.0\n",
      "976059  VZ01  100520431000002      2020-02-02    2020-02-13     8.0\n",
      "981795  VZ01  100520431000002      2020-02-14    2023-11-27     0.0\n",
      "\n",
      "[740 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(warehouse_data[warehouse_data['sku'].isin([100630105000002, 100259022000005, 100259021000006, 100654238000002, 100259022000002, 100520431000002])])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store: VZ01\n",
      "--- 0.04602789878845215 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/p02my_xx7t193mwjyb2ytt040000gn/T/ipykernel_98535/56465913.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  warehouse_data_sample['valid_from_date'] = pd.to_datetime(warehouse_data_sample['valid_from_date'])\n",
      "/var/folders/sv/p02my_xx7t193mwjyb2ytt040000gn/T/ipykernel_98535/56465913.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  warehouse_data_sample['valid_to_date'] = pd.to_datetime(warehouse_data_sample['valid_to_date'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "warehouse_data['valid_from_date'] = pd.to_datetime(warehouse_data['valid_from_date'])\n",
    "warehouse_data['valid_to_date'] = pd.to_datetime(warehouse_data['valid_to_date'])\n",
    "warehouse_data = warehouse_data.sort_values('valid_from_date')\n",
    "warehouse_data['sku_store'] = warehouse_data['sku'].astype(str) + ',' + warehouse_data['store'].astype(str)\n",
    "warehouse_data_sample = warehouse_data[warehouse_data['sku'].isin(sku_unique_in_sales)]\n",
    "for store in ['VZ01']:\n",
    "    print(\"store:\", store)\n",
    "\n",
    "    warehouse_data_sample['valid_from_date'] = pd.to_datetime(warehouse_data_sample['valid_from_date'])\n",
    "    warehouse_data_sample['valid_to_date'] = pd.to_datetime(warehouse_data_sample['valid_to_date'])\n",
    "    filtered_warehouse_data = warehouse_data_sample\n",
    "\n",
    "    # Function to generate date ranges\n",
    "    def generate_date_ranges(row):\n",
    "        return pd.date_range(row['valid_from_date'], row['valid_to_date'])\n",
    "\n",
    "    # Apply function to create date ranges\n",
    "    df_all_2 = filtered_warehouse_data.apply(generate_date_ranges, axis=1)\n",
    "\n",
    "    # Create DataFrame with SKU-store and dates\n",
    "    df_all_2 = pd.DataFrame({\n",
    "        'sku': np.repeat(filtered_warehouse_data['sku'].values, df_all_2.str.len()),\n",
    "        'date': np.concatenate(df_all_2.values)  # Convert DatetimeIndex to array for concatenation\n",
    "    })\n",
    "    df_all_2 = pd.merge(df_all_2, filtered_warehouse_data[['sku','valid_from_date', 'stock']], left_on=['sku', 'date'], right_on=['sku', 'valid_from_date'], how='left')\n",
    "    # ffil stock\n",
    "    df_all_2['stock'] = df_all_2['stock'].ffill()\n",
    "  #  df_all_2 = df_all_2.rename(columns={'stock':'warehouse stock'})\n",
    "    df_all_2 = df_all_2.drop(columns=['valid_from_date'])\n",
    "\n",
    "    df_all_2.to_parquet(\"/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/reinforcment_codes/datasets_4/df_all_store_{}.parquet\".format(store))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "                  sku       date  stock\n0     100520431000002 2017-12-29  927.0\n1     100520431000002 2017-12-30  927.0\n2     100520431000002 2017-12-31  927.0\n3     100520431000002 2018-01-01  927.0\n4     100520431000002 2018-01-02  927.0\n...               ...        ...    ...\n5304  100654238000002 2023-11-23    0.0\n5305  100654238000002 2023-11-24    0.0\n5306  100654238000002 2023-11-25    0.0\n5307  100654238000002 2023-11-26    0.0\n5308  100654238000002 2023-11-27    0.0\n\n[5309 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sku</th>\n      <th>date</th>\n      <th>stock</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100520431000002</td>\n      <td>2017-12-29</td>\n      <td>927.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100520431000002</td>\n      <td>2017-12-30</td>\n      <td>927.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100520431000002</td>\n      <td>2017-12-31</td>\n      <td>927.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100520431000002</td>\n      <td>2018-01-01</td>\n      <td>927.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100520431000002</td>\n      <td>2018-01-02</td>\n      <td>927.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5304</th>\n      <td>100654238000002</td>\n      <td>2023-11-23</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5305</th>\n      <td>100654238000002</td>\n      <td>2023-11-24</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5306</th>\n      <td>100654238000002</td>\n      <td>2023-11-25</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5307</th>\n      <td>100654238000002</td>\n      <td>2023-11-26</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5308</th>\n      <td>100654238000002</td>\n      <td>2023-11-27</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5309 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2.to_parquet(\"df_all_store_{}.parquet\".format(store))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2['sku_store'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data_sample[warehouse_data_sample['sku'] == '100657013000006']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_sku_stores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mbew_fashion[mbew_fashion['sku_store'] == '100090812000001,100']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2[df_all_2['sku_store'] == '100090812000001,100']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_warehouse_df_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(100630490000005)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
