{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/f_sales_v_fashion.csv')\n",
    "sales_data['date'] = pd.to_datetime(sales_data['date'])\n",
    "sales_data['store'] = sales_data['store'].astype(str)\n",
    "sales_data = sales_data.rename(columns={'total_sales':'sales'})\n",
    "sales_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sales_data['sku'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data = pd.read_csv('/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/warehouse_stock_fashion.csv')\n",
    "warehouse_data['valid_to_date'] = warehouse_data['valid_to_date'].replace('2099-12-31', sales_data['date'].max().strftime('%Y-%m-%d'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list1 = set(warehouse_data[warehouse_data['stock'] > 0 ]['sku'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list2 = set(sales_data[(sales_data['date'] > '2019-01-01') & (sales_data['sales'] > 0)]['sku'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_intersection = list1.intersection(list2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skus = list(list_intersection)[:100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sales_data = sales_data[sales_data['sku'].isin(skus)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data = warehouse_data[warehouse_data['sku'].isin(skus)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data['valid_to_date'].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mbew_fashion = pd.read_csv('mbew_fashion.csv')\n",
    "mbew_fashion['valid_to_date'] = mbew_fashion['valid_to_date'].replace('2099-12-31', sales_data['date'].max().strftime('%Y-%m-%d'))\n",
    "mbew_fashion['valid_to_date'] = pd.to_datetime(mbew_fashion['valid_to_date'])\n",
    "mbew_fashion['valid_from_date'] = pd.to_datetime(mbew_fashion['valid_from_date'])\n",
    "mbew_fashion['item'] = mbew_fashion['sku'].astype(str).str[:12]\n",
    "mbew_fashion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mbew_fashion.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mbew_fashion = mbew_fashion[mbew_fashion['sku'].isin(skus)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mbew_fashion_no_zero = mbew_fashion[mbew_fashion['stock'] > 0]\n",
    "mbew_fashion_no_zero['valid_from_date'] = pd.to_datetime(mbew_fashion_no_zero['valid_from_date'])\n",
    "dict_of_first_month_date_for_sku = {}\n",
    "i= 0\n",
    "for sku in mbew_fashion_no_zero['sku'].unique():\n",
    "    i+=1\n",
    "    print(str(i) + ' out of ' + str(len(mbew_fashion_no_zero['sku'].unique())))\n",
    "    data_ = mbew_fashion_no_zero[mbew_fashion_no_zero['sku'] == sku]\n",
    "    first_date = data_['valid_from_date'].min()\n",
    "    # put the month in the dict from the first date\n",
    "    dict_of_first_month_date_for_sku[sku] =  first_date.strftime('%m/%y')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mbew_fashion['sku'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# take MM/YY from first date\n",
    "first_date.strftime('%m/%y')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strong_sku = sales_data.groupby(['sku'])['sales'].sum().sort_values(ascending=False).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for sku in [100630490000001, 100630490000002, 100630490000003, 100630490000004, 100630490000005, 100630490000006, 100630490000007, 100630490000008, 100630490000009, 100630490000010, 100630490000011, 100630490000012, 100630490000013, 100630490000014, 100630490000015, 100630490000016, 100630490000017, 100630490000018, 100630490000019, 100630490000020, 100630490000021,]:\n",
    "#     sku_data = sales_data[sales_data['sku'] == sku].groupby('date')['sales'].sum()\n",
    "#     sku_data = sku_data.reindex(pd.date_range(start=sales_data['date'].min(),\n",
    "#                                                 # today\n",
    "#                                                 end=sales_data['date'].max(),\n",
    "#\n",
    "#                                                 freq='D')).fillna(0)\n",
    "#     sku_warehouse = warehouse_data[warehouse_data['sku'].astype(str) == str(sku)].sort_values(by='valid_from_date')\n",
    "#     sku_warehouse_df_final = pd.DataFrame()\n",
    "#     for row in sku_warehouse.iterrows():\n",
    "#         sku_warehouse_df_final = pd.concat([sku_warehouse_df_final, pd.DataFrame({'date':pd.date_range(start=row[1]['valid_from_date'], end=row[1]['valid_to_date'], freq='D'), 'warehouse stock':row[1]['stock']})])\n",
    "#     sku_warehouse_df_final = sku_warehouse_df_final.set_index('date')\n",
    "#     relevant_sku_stores_stock = mbew_fashion[mbew_fashion['sku'] == sku]\n",
    "#     all_stores_sku_stock_data = {}\n",
    "#     for store in relevant_sku_stores_stock['store'].unique():\n",
    "#         store_sku_data = relevant_sku_stores_stock[relevant_sku_stores_stock['store'] == store]\n",
    "#         one_store_stock_sku_all = pd.DataFrame()\n",
    "#         for row in store_sku_data.iterrows():\n",
    "#             one_store_stock_sku = pd.DataFrame({'date':pd.date_range(start=row[1]['valid_from_date'],\n",
    "#                                                                      end=row[1]['valid_to_date'],\n",
    "#                                                                      freq='D'),\n",
    "#                                                 'store stock':row[1]['stock']})\n",
    "#             one_store_stock_sku_all = pd.concat([one_store_stock_sku_all, one_store_stock_sku])\n",
    "#         one_store_stock_sku_all = one_store_stock_sku_all.set_index('date')\n",
    "#         all_stores_sku_stock_data[store] = one_store_stock_sku_all\n",
    "#         # merge all stores with outer join\n",
    "#     all_stores_final_stock_data = pd.DataFrame()\n",
    "#     for store in all_stores_sku_stock_data.keys():\n",
    "#         relevant_store_data_1 = all_stores_sku_stock_data[store]\n",
    "#         relevant_store_data_1 = relevant_store_data_1.rename(columns={'store stock':'store {}'.format(store) + ' stock'})\n",
    "#         all_stores_final_stock_data = pd.concat([all_stores_final_stock_data, relevant_store_data_1], axis=1, join='outer')\n",
    "#     all_store_sum_stock = all_stores_final_stock_data.sum(axis=1).to_frame().rename(columns={0:'all stores stock'})\n",
    "#     # merge by index\n",
    "#     sku_data = pd.merge(sku_data, sku_warehouse_df_final, left_index=True, right_index=True, how='left').fillna(0)\n",
    "#     sku_data = pd.merge(sku_data, all_store_sum_stock, left_index=True, right_index=True, how='left').fillna(0)\n",
    "#     sku_data_w = sku_data.resample('W').agg({'sales':'sum', 'warehouse stock':'mean', 'all stores stock':'mean'})\n",
    "#     sku_data_w.plot(figsize=(20,4))\n",
    "#     plt.title('sku: ' + str(sku))\n",
    "#\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_warehouse = warehouse_data[warehouse_data['sku'].astype(str) == str(sku)].sort_values(by='valid_from_date')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sales_data['sku_store'] = sales_data['sku'].astype(str) + ',' + sales_data['store'].astype(str)\n",
    "mbew_fashion['sku_store'] = mbew_fashion['sku'].astype(str) + ',' + mbew_fashion['store'].astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "mbew_fashion = mbew_fashion.sort_values('valid_from_date')\n",
    "\n",
    "for store in sales_data['store'].unique():\n",
    "    print(\"store:\", store)\n",
    "    len_of_store = sales_data[sales_data['store'] == store][\"sku_store\"].nunique()\n",
    "\n",
    "    unique_sku_stores =  sales_data[sales_data['store'] == store][\"sku_store\"].unique()\n",
    "\n",
    "    mbew_fashion['valid_from_date'] = pd.to_datetime(mbew_fashion['valid_from_date'])\n",
    "    mbew_fashion['valid_to_date'] = pd.to_datetime(mbew_fashion['valid_to_date'])\n",
    "    filtered_mbew_fashion = mbew_fashion[mbew_fashion['sku_store'].isin(unique_sku_stores)]\n",
    "\n",
    "    # Function to generate date ranges\n",
    "    def generate_date_ranges(row):\n",
    "        return pd.date_range(row['valid_from_date'], row['valid_to_date'])\n",
    "\n",
    "    # Apply function to create date ranges\n",
    "    df_all_2 = filtered_mbew_fashion.apply(generate_date_ranges, axis=1)\n",
    "\n",
    "    # Create DataFrame with SKU-store and dates\n",
    "    df_all_2 = pd.DataFrame({\n",
    "        'sku_store': np.repeat(filtered_mbew_fashion['sku_store'].values, df_all_2.str.len()),\n",
    "        'date': np.concatenate(df_all_2.values)  # Convert DatetimeIndex to array for concatenation\n",
    "    })\n",
    "    # merge left by ['sku_store', 'date'] and right by ['sku_store', 'valid_to_date']\n",
    "    df_all_2 = pd.merge(df_all_2, filtered_mbew_fashion[['sku_store','valid_from_date', 'stock']], left_on=['sku_store', 'date'], right_on=['sku_store', 'valid_from_date'], how='left')\n",
    "    # ffil stock\n",
    "    df_all_2['stock'] = df_all_2['stock'].ffill()\n",
    "    df_all_2 = df_all_2.drop(columns=['valid_from_date'])\n",
    "    df_all_2 = pd.merge(sales_data, df_all_2, on=[\"sku_store\",\"date\"], how=\"right\")\n",
    "    df_all_2['sku'] = df_all_2['sku_store'].str.split(',').str[0]\n",
    "    df_all_2['store'] = df_all_2['sku_store'].str.split(',').str[1]\n",
    "    df_all_2['item'] = df_all_2['sku'].astype(str).str[:12]\n",
    "    df_all_2['sales'] = df_all_2['sales'].fillna(0)\n",
    "    df_all_2.to_parquet(\"/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/reinforcment_codes/datasets_4/df_all_store_{}.parquet\".format(store))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# generate warehouse data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_unique_in_sales = sales_data['sku'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(warehouse_data[warehouse_data['sku'].isin(skus)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "warehouse_data['valid_from_date'] = pd.to_datetime(warehouse_data['valid_from_date'])\n",
    "warehouse_data['valid_to_date'] = pd.to_datetime(warehouse_data['valid_to_date'])\n",
    "warehouse_data = warehouse_data.sort_values('valid_from_date')\n",
    "warehouse_data['sku_store'] = warehouse_data['sku'].astype(str) + ',' + warehouse_data['store'].astype(str)\n",
    "warehouse_data_sample = warehouse_data[warehouse_data['sku'].isin(sku_unique_in_sales)]\n",
    "for store in ['VZ01']:\n",
    "    print(\"store:\", store)\n",
    "\n",
    "    warehouse_data_sample['valid_from_date'] = pd.to_datetime(warehouse_data_sample['valid_from_date'])\n",
    "    warehouse_data_sample['valid_to_date'] = pd.to_datetime(warehouse_data_sample['valid_to_date'])\n",
    "    filtered_warehouse_data = warehouse_data_sample\n",
    "\n",
    "    # Function to generate date ranges\n",
    "    def generate_date_ranges(row):\n",
    "        return pd.date_range(row['valid_from_date'], row['valid_to_date'])\n",
    "\n",
    "    # Apply function to create date ranges\n",
    "    df_all_2 = filtered_warehouse_data.apply(generate_date_ranges, axis=1)\n",
    "\n",
    "    # Create DataFrame with SKU-store and dates\n",
    "    df_all_2 = pd.DataFrame({\n",
    "        'sku': np.repeat(filtered_warehouse_data['sku'].values, df_all_2.str.len()),\n",
    "        'date': np.concatenate(df_all_2.values)  # Convert DatetimeIndex to array for concatenation\n",
    "    })\n",
    "    df_all_2 = pd.merge(df_all_2, filtered_warehouse_data[['sku','valid_from_date', 'stock']], left_on=['sku', 'date'], right_on=['sku', 'valid_from_date'], how='left')\n",
    "    # ffil stock\n",
    "    df_all_2['stock'] = df_all_2['stock'].ffill()\n",
    "  #  df_all_2 = df_all_2.rename(columns={'stock':'warehouse stock'})\n",
    "    df_all_2 = df_all_2.drop(columns=['valid_from_date'])\n",
    "\n",
    "    df_all_2.to_parquet(\"/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/reinforcment_codes/datasets_4/df_all_store_{}.parquet\".format(store))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2.to_parquet(\"df_all_store_{}.parquet\".format(store))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2['sku_store'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data_sample[warehouse_data_sample['sku'] == '100657013000006']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_sku_stores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mbew_fashion[mbew_fashion['sku_store'] == '100090812000001,100']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2[df_all_2['sku_store'] == '100090812000001,100']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_warehouse_df_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(100630490000005)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
