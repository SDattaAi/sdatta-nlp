{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4990977 entries, 0 to 4990976\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   sku                      int64         \n",
      " 1   store                    object        \n",
      " 2   date                     datetime64[ns]\n",
      " 3   average_price            float64       \n",
      " 4   average_dicounted_price  float64       \n",
      " 5   sales                    float64       \n",
      " 6   item                     object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(2)\n",
      "memory usage: 266.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sales_data = pd.read_csv('/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/f_sales_v_fashion.csv')\n",
    "sales_data['date'] = pd.to_datetime(sales_data['date'])\n",
    "sales_data['item'] = sales_data['sku'].astype(str)\n",
    "sales_data['store'] = sales_data['store'].astype(str)\n",
    "sales_data = sales_data.rename(columns={'total_sales':'sales'})\n",
    "sales_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "sales_data = sales_data[sales_data['sku'] == 100630105000002]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "warehouse_data = pd.read_csv('/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/warehouse_stock_fashion.csv')\n",
    "warehouse_data['valid_to_date'] = warehouse_data['valid_to_date'].replace('2099-12-31', sales_data['date'].max().strftime('%Y-%m-%d'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1356889 entries, 0 to 1356888\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   store            1356889 non-null  object \n",
      " 1   sku              1356889 non-null  int64  \n",
      " 2   valid_from_date  1356889 non-null  object \n",
      " 3   valid_to_date    1356889 non-null  object \n",
      " 4   stock            1356889 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 51.8+ MB\n"
     ]
    }
   ],
   "source": [
    "warehouse_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "warehouse_data = warehouse_data[warehouse_data['sku'] == 100630105000002]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'2022-03-25'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warehouse_data['valid_to_date'].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "          store              sku valid_from_date valid_to_date  stock  \\\n0           123  100549055000004      2017-04-21    2022-03-25    0.0   \n1            89  100532175000001      2017-04-21    2022-03-25    0.0   \n2            43  100553018000001      2017-04-21    2022-03-25    0.0   \n3           104  100548169000007      2017-04-21    2022-03-25    0.0   \n4            85  100549049000003      2017-04-21    2022-03-25    0.0   \n...         ...              ...             ...           ...    ...   \n17812117     18  100552850000002      2020-05-07    2022-03-25    0.0   \n17812118     99  100653096000013      2020-05-07    2020-08-14    1.0   \n17812119     46  100557049000004      2018-11-17    2022-03-25    0.0   \n17812120      8  100511203000004      2017-04-21    2022-03-25    0.0   \n17812121   3202  100542009000007      2017-04-21    2022-03-25    0.0   \n\n                  item  \n0         100549055000  \n1         100532175000  \n2         100553018000  \n3         100548169000  \n4         100549049000  \n...                ...  \n17812117  100552850000  \n17812118  100653096000  \n17812119  100557049000  \n17812120  100511203000  \n17812121  100542009000  \n\n[17812122 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store</th>\n      <th>sku</th>\n      <th>valid_from_date</th>\n      <th>valid_to_date</th>\n      <th>stock</th>\n      <th>item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>123</td>\n      <td>100549055000004</td>\n      <td>2017-04-21</td>\n      <td>2022-03-25</td>\n      <td>0.0</td>\n      <td>100549055000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>89</td>\n      <td>100532175000001</td>\n      <td>2017-04-21</td>\n      <td>2022-03-25</td>\n      <td>0.0</td>\n      <td>100532175000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>43</td>\n      <td>100553018000001</td>\n      <td>2017-04-21</td>\n      <td>2022-03-25</td>\n      <td>0.0</td>\n      <td>100553018000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104</td>\n      <td>100548169000007</td>\n      <td>2017-04-21</td>\n      <td>2022-03-25</td>\n      <td>0.0</td>\n      <td>100548169000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>85</td>\n      <td>100549049000003</td>\n      <td>2017-04-21</td>\n      <td>2022-03-25</td>\n      <td>0.0</td>\n      <td>100549049000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17812117</th>\n      <td>18</td>\n      <td>100552850000002</td>\n      <td>2020-05-07</td>\n      <td>2022-03-25</td>\n      <td>0.0</td>\n      <td>100552850000</td>\n    </tr>\n    <tr>\n      <th>17812118</th>\n      <td>99</td>\n      <td>100653096000013</td>\n      <td>2020-05-07</td>\n      <td>2020-08-14</td>\n      <td>1.0</td>\n      <td>100653096000</td>\n    </tr>\n    <tr>\n      <th>17812119</th>\n      <td>46</td>\n      <td>100557049000004</td>\n      <td>2018-11-17</td>\n      <td>2022-03-25</td>\n      <td>0.0</td>\n      <td>100557049000</td>\n    </tr>\n    <tr>\n      <th>17812120</th>\n      <td>8</td>\n      <td>100511203000004</td>\n      <td>2017-04-21</td>\n      <td>2022-03-25</td>\n      <td>0.0</td>\n      <td>100511203000</td>\n    </tr>\n    <tr>\n      <th>17812121</th>\n      <td>3202</td>\n      <td>100542009000007</td>\n      <td>2017-04-21</td>\n      <td>2022-03-25</td>\n      <td>0.0</td>\n      <td>100542009000</td>\n    </tr>\n  </tbody>\n</table>\n<p>17812122 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbew_fashion = pd.read_csv('mbew_fashion.csv')\n",
    "mbew_fashion['valid_to_date'] = mbew_fashion['valid_to_date'].replace('2099-12-31', sales_data['date'].max().strftime('%Y-%m-%d'))\n",
    "mbew_fashion['valid_to_date'] = pd.to_datetime(mbew_fashion['valid_to_date'])\n",
    "mbew_fashion['valid_from_date'] = pd.to_datetime(mbew_fashion['valid_from_date'])\n",
    "mbew_fashion['item'] = mbew_fashion['sku'].astype(str).str[:12]\n",
    "mbew_fashion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17812122 entries, 0 to 17812121\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   store            int64         \n",
      " 1   sku              int64         \n",
      " 2   valid_from_date  datetime64[ns]\n",
      " 3   valid_to_date    datetime64[ns]\n",
      " 4   stock            float64       \n",
      " 5   item             object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(2), object(1)\n",
      "memory usage: 815.4+ MB\n"
     ]
    }
   ],
   "source": [
    "mbew_fashion.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "mbew_fashion = mbew_fashion[mbew_fashion['sku'] == 100630105000002]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/p02my_xx7t193mwjyb2ytt040000gn/T/ipykernel_52943/154987957.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mbew_fashion_no_zero['valid_from_date'] = pd.to_datetime(mbew_fashion_no_zero['valid_from_date'])\n"
     ]
    }
   ],
   "source": [
    "mbew_fashion_no_zero = mbew_fashion[mbew_fashion['stock'] > 0]\n",
    "mbew_fashion_no_zero['valid_from_date'] = pd.to_datetime(mbew_fashion_no_zero['valid_from_date'])\n",
    "dict_of_first_month_date_for_sku = {}\n",
    "i= 0\n",
    "for sku in mbew_fashion_no_zero['sku'].unique():\n",
    "    i+=1\n",
    "    print(str(i) + ' out of ' + str(len(mbew_fashion_no_zero['sku'].unique())))\n",
    "    data_ = mbew_fashion_no_zero[mbew_fashion_no_zero['sku'] == sku]\n",
    "    first_date = data_['valid_from_date'].min()\n",
    "    # put the month in the dict from the first date\n",
    "    dict_of_first_month_date_for_sku[sku] =  first_date.strftime('%m/%y')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'09/20'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take MM/YY from first date\n",
    "first_date.strftime('%m/%y')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_of_first_day_for_sku' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdict_of_first_day_for_sku\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dict_of_first_day_for_sku' is not defined"
     ]
    }
   ],
   "source": [
    "dict_of_first_day_for_sku"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     sku store       date  average_price  \\\n",
      "2977904  100630105000002    10 2020-09-15          24.99   \n",
      "2977905  100630105000002    10 2020-09-16          24.99   \n",
      "2977906  100630105000002    10 2020-09-19          24.99   \n",
      "2977907  100630105000002    10 2020-09-24          24.99   \n",
      "2977908  100630105000002    10 2020-10-01          24.99   \n",
      "...                  ...   ...        ...            ...   \n",
      "2979597  100630105000002    99 2021-03-03          24.99   \n",
      "2979598  100630105000002    99 2021-03-12          24.99   \n",
      "2979599  100630105000002    99 2021-03-13          24.99   \n",
      "2979600  100630105000002    99 2021-05-03          24.99   \n",
      "2979601  100630105000002    99 2021-06-05          24.99   \n",
      "\n",
      "         average_dicounted_price  sales             item  \n",
      "2977904                    24.99    1.0  100630105000002  \n",
      "2977905                    24.99    1.0  100630105000002  \n",
      "2977906                    24.99    1.0  100630105000002  \n",
      "2977907                    14.99    1.0  100630105000002  \n",
      "2977908                    19.99    2.0  100630105000002  \n",
      "...                          ...    ...              ...  \n",
      "2979597                    24.99    1.0  100630105000002  \n",
      "2979598                    19.99    1.0  100630105000002  \n",
      "2979599                    24.99    2.0  100630105000002  \n",
      "2979600                    19.99    1.0  100630105000002  \n",
      "2979601                    24.99    1.0  100630105000002  \n",
      "\n",
      "[1698 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sales_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "strong_sku = sales_data.groupby(['sku'])['sales'].sum().sort_values(ascending=False).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m sku_warehouse\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[1;32m     12\u001B[0m     sku_warehouse_df_final \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([sku_warehouse_df_final, pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m:pd\u001B[38;5;241m.\u001B[39mdate_range(start\u001B[38;5;241m=\u001B[39mrow[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid_from_date\u001B[39m\u001B[38;5;124m'\u001B[39m], end\u001B[38;5;241m=\u001B[39mrow[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid_to_date\u001B[39m\u001B[38;5;124m'\u001B[39m], freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwarehouse stock\u001B[39m\u001B[38;5;124m'\u001B[39m:row[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstock\u001B[39m\u001B[38;5;124m'\u001B[39m]})])\n\u001B[0;32m---> 13\u001B[0m sku_warehouse_df_final \u001B[38;5;241m=\u001B[39m \u001B[43msku_warehouse_df_final\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_index\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m relevant_sku_stores_stock \u001B[38;5;241m=\u001B[39m mbew_fashion[mbew_fashion[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msku\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m sku]\n\u001B[1;32m     15\u001B[0m all_stores_sku_stock_data \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/Desktop/Palmers/palmers/venv/local_oran/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Palmers/palmers/venv/local_oran/lib/python3.9/site-packages/pandas/core/frame.py:6012\u001B[0m, in \u001B[0;36mDataFrame.set_index\u001B[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001B[0m\n\u001B[1;32m   6009\u001B[0m                 missing\u001B[38;5;241m.\u001B[39mappend(col)\n\u001B[1;32m   6011\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m missing:\n\u001B[0;32m-> 6012\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m are in the columns\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6014\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   6015\u001B[0m     frame \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of ['date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for sku in [100630490000001, 100630490000002, 100630490000003, 100630490000004, 100630490000005, 100630490000006, 100630490000007, 100630490000008, 100630490000009, 100630490000010, 100630490000011, 100630490000012, 100630490000013, 100630490000014, 100630490000015, 100630490000016, 100630490000017, 100630490000018, 100630490000019, 100630490000020, 100630490000021,]:\n",
    "    sku_data = sales_data[sales_data['sku'] == sku].groupby('date')['sales'].sum()\n",
    "    sku_data = sku_data.reindex(pd.date_range(start=sales_data['date'].min(),\n",
    "                                                # today\n",
    "                                                end=sales_data['date'].max(),\n",
    "\n",
    "                                                freq='D')).fillna(0)\n",
    "    sku_warehouse = warehouse_data[warehouse_data['sku'].astype(str) == str(sku)].sort_values(by='valid_from_date')\n",
    "    sku_warehouse_df_final = pd.DataFrame()\n",
    "    for row in sku_warehouse.iterrows():\n",
    "        sku_warehouse_df_final = pd.concat([sku_warehouse_df_final, pd.DataFrame({'date':pd.date_range(start=row[1]['valid_from_date'], end=row[1]['valid_to_date'], freq='D'), 'warehouse stock':row[1]['stock']})])\n",
    "    sku_warehouse_df_final = sku_warehouse_df_final.set_index('date')\n",
    "    relevant_sku_stores_stock = mbew_fashion[mbew_fashion['sku'] == sku]\n",
    "    all_stores_sku_stock_data = {}\n",
    "    for store in relevant_sku_stores_stock['store'].unique():\n",
    "        store_sku_data = relevant_sku_stores_stock[relevant_sku_stores_stock['store'] == store]\n",
    "        one_store_stock_sku_all = pd.DataFrame()\n",
    "        for row in store_sku_data.iterrows():\n",
    "            one_store_stock_sku = pd.DataFrame({'date':pd.date_range(start=row[1]['valid_from_date'],\n",
    "                                                                     end=row[1]['valid_to_date'],\n",
    "                                                                     freq='D'),\n",
    "                                                'store stock':row[1]['stock']})\n",
    "            one_store_stock_sku_all = pd.concat([one_store_stock_sku_all, one_store_stock_sku])\n",
    "        one_store_stock_sku_all = one_store_stock_sku_all.set_index('date')\n",
    "        all_stores_sku_stock_data[store] = one_store_stock_sku_all\n",
    "        # merge all stores with outer join\n",
    "    all_stores_final_stock_data = pd.DataFrame()\n",
    "    for store in all_stores_sku_stock_data.keys():\n",
    "        relevant_store_data_1 = all_stores_sku_stock_data[store]\n",
    "        relevant_store_data_1 = relevant_store_data_1.rename(columns={'store stock':'store {}'.format(store) + ' stock'})\n",
    "        all_stores_final_stock_data = pd.concat([all_stores_final_stock_data, relevant_store_data_1], axis=1, join='outer')\n",
    "    all_store_sum_stock = all_stores_final_stock_data.sum(axis=1).to_frame().rename(columns={0:'all stores stock'})\n",
    "    # merge by index\n",
    "    sku_data = pd.merge(sku_data, sku_warehouse_df_final, left_index=True, right_index=True, how='left').fillna(0)\n",
    "    sku_data = pd.merge(sku_data, all_store_sum_stock, left_index=True, right_index=True, how='left').fillna(0)\n",
    "    sku_data_w = sku_data.resample('W').agg({'sales':'sum', 'warehouse stock':'mean', 'all stores stock':'mean'})\n",
    "    sku_data_w.plot(figsize=(20,4))\n",
    "    plt.title('sku: ' + str(sku))\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "sku_warehouse = warehouse_data[warehouse_data['sku'].astype(str) == str(sku)].sort_values(by='valid_from_date')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/p02my_xx7t193mwjyb2ytt040000gn/T/ipykernel_52943/3695414943.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mbew_fashion['sku_store'] = mbew_fashion['sku'].astype(str) + ',' + mbew_fashion['store'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "sales_data['sku_store'] = sales_data['sku'].astype(str) + ',' + sales_data['store'].astype(str)\n",
    "mbew_fashion['sku_store'] = mbew_fashion['sku'].astype(str) + ',' + mbew_fashion['store'].astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store: 10\n",
      "store: 100\n",
      "store: 104\n",
      "store: 105\n",
      "store: 106\n",
      "store: 109\n",
      "store: 11\n",
      "store: 114\n",
      "store: 117\n",
      "store: 119\n",
      "store: 121\n",
      "store: 122\n",
      "store: 123\n",
      "store: 130\n",
      "store: 133\n",
      "store: 135\n",
      "store: 136\n",
      "store: 141\n",
      "store: 143\n",
      "store: 144\n",
      "store: 147\n",
      "store: 149\n",
      "store: 15\n",
      "store: 150\n",
      "store: 152\n",
      "store: 156\n",
      "store: 159\n",
      "store: 160\n",
      "store: 162\n",
      "store: 163\n",
      "store: 164\n",
      "store: 166\n",
      "store: 167\n",
      "store: 168\n",
      "store: 170\n",
      "store: 171\n",
      "store: 172\n",
      "store: 173\n",
      "store: 174\n",
      "store: 175\n",
      "store: 179\n",
      "store: 18\n",
      "store: 180\n",
      "store: 181\n",
      "store: 182\n",
      "store: 183\n",
      "store: 184\n",
      "store: 185\n",
      "store: 186\n",
      "store: 188\n",
      "store: 189\n",
      "store: 201\n",
      "store: 202\n",
      "store: 203\n",
      "store: 21\n",
      "store: 213\n",
      "store: 214\n",
      "store: 215\n",
      "store: 216\n",
      "store: 217\n",
      "store: 218\n",
      "store: 219\n",
      "store: 22\n",
      "store: 220\n",
      "store: 221\n",
      "store: 225\n",
      "store: 26\n",
      "store: 27\n",
      "store: 28\n",
      "store: 29\n",
      "store: 3\n",
      "store: 3005\n",
      "store: 3202\n",
      "store: 3205\n",
      "store: 3208\n",
      "store: 3245\n",
      "store: 35\n",
      "store: 36\n",
      "store: 37\n",
      "store: 4\n",
      "store: 4104\n",
      "store: 4123\n",
      "store: 4129\n",
      "store: 4133\n",
      "store: 4134\n",
      "store: 42\n",
      "store: 43\n",
      "store: 44\n",
      "store: 45\n",
      "store: 46\n",
      "store: 47\n",
      "store: 4803\n",
      "store: 4805\n",
      "store: 4904\n",
      "store: 4906\n",
      "store: 5\n",
      "store: 50\n",
      "store: 51\n",
      "store: 52\n",
      "store: 55\n",
      "store: 56\n",
      "store: 57\n",
      "store: 61\n",
      "store: 63\n",
      "store: 64\n",
      "store: 67\n",
      "store: 68\n",
      "store: 69\n",
      "store: 7\n",
      "store: 73\n",
      "store: 74\n",
      "store: 76\n",
      "store: 79\n",
      "store: 8\n",
      "store: 81\n",
      "store: 82\n",
      "store: 84\n",
      "store: 85\n",
      "store: 88\n",
      "store: 89\n",
      "store: 90\n",
      "store: 91\n",
      "store: 95\n",
      "store: 96\n",
      "store: 99\n",
      "--- 1.531559944152832 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "mbew_fashion = mbew_fashion.sort_values('valid_from_date')\n",
    "\n",
    "for store in sales_data['store'].unique():\n",
    "    print(\"store:\", store)\n",
    "    len_of_store = sales_data[sales_data['store'] == store][\"sku_store\"].nunique()\n",
    "\n",
    "    unique_sku_stores =  sales_data[sales_data['store'] == store][\"sku_store\"].unique()\n",
    "\n",
    "    mbew_fashion['valid_from_date'] = pd.to_datetime(mbew_fashion['valid_from_date'])\n",
    "    mbew_fashion['valid_to_date'] = pd.to_datetime(mbew_fashion['valid_to_date'])\n",
    "    filtered_mbew_fashion = mbew_fashion[mbew_fashion['sku_store'].isin(unique_sku_stores)]\n",
    "\n",
    "    # Function to generate date ranges\n",
    "    def generate_date_ranges(row):\n",
    "        return pd.date_range(row['valid_from_date'], row['valid_to_date'])\n",
    "\n",
    "    # Apply function to create date ranges\n",
    "    df_all_2 = filtered_mbew_fashion.apply(generate_date_ranges, axis=1)\n",
    "\n",
    "    # Create DataFrame with SKU-store and dates\n",
    "    df_all_2 = pd.DataFrame({\n",
    "        'sku_store': np.repeat(filtered_mbew_fashion['sku_store'].values, df_all_2.str.len()),\n",
    "        'date': np.concatenate(df_all_2.values)  # Convert DatetimeIndex to array for concatenation\n",
    "    })\n",
    "    # merge left by ['sku_store', 'date'] and right by ['sku_store', 'valid_to_date']\n",
    "    df_all_2 = pd.merge(df_all_2, filtered_mbew_fashion[['sku_store','valid_from_date', 'stock']], left_on=['sku_store', 'date'], right_on=['sku_store', 'valid_from_date'], how='left')\n",
    "    # ffil stock\n",
    "    df_all_2['stock'] = df_all_2['stock'].ffill()\n",
    "    df_all_2 = df_all_2.drop(columns=['valid_from_date'])\n",
    "    df_all_2 = pd.merge(sales_data, df_all_2, on=[\"sku_store\",\"date\"], how=\"right\")\n",
    "    df_all_2['sku'] = df_all_2['sku_store'].str.split(',').str[0]\n",
    "    df_all_2['store'] = df_all_2['sku_store'].str.split(',').str[1]\n",
    "    df_all_2['item'] = df_all_2['sku'].astype(str).str[:12]\n",
    "    df_all_2['sales'] = df_all_2['sales'].fillna(0)\n",
    "    df_all_2.to_parquet(\"/Users/guybasson/Desktop/sdatta-nlp/palmers_fashion/reinforcment_codes/datasets_3/df_all_store_{}.parquet\".format(store))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# generate warehouse data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_unique_in_sales = sales_data['sku'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(warehouse_data[warehouse_data['sku'].isin([100642246000001])])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "warehouse_data['valid_from_date'] = pd.to_datetime(warehouse_data['valid_from_date'])\n",
    "warehouse_data['valid_to_date'] = pd.to_datetime(warehouse_data['valid_to_date'])\n",
    "warehouse_data = warehouse_data.sort_values('valid_from_date')\n",
    "warehouse_data['sku_store'] = warehouse_data['sku'].astype(str) + ',' + warehouse_data['store'].astype(str)\n",
    "warehouse_data_sample = warehouse_data[warehouse_data['sku'].isin(sku_unique_in_sales)]\n",
    "for store in ['VZ01']:\n",
    "    print(\"store:\", store)\n",
    "\n",
    "    warehouse_data_sample['valid_from_date'] = pd.to_datetime(warehouse_data_sample['valid_from_date'])\n",
    "    warehouse_data_sample['valid_to_date'] = pd.to_datetime(warehouse_data_sample['valid_to_date'])\n",
    "    filtered_warehouse_data = warehouse_data_sample\n",
    "\n",
    "    # Function to generate date ranges\n",
    "    def generate_date_ranges(row):\n",
    "        return pd.date_range(row['valid_from_date'], row['valid_to_date'])\n",
    "\n",
    "    # Apply function to create date ranges\n",
    "    df_all_2 = filtered_warehouse_data.apply(generate_date_ranges, axis=1)\n",
    "\n",
    "    # Create DataFrame with SKU-store and dates\n",
    "    df_all_2 = pd.DataFrame({\n",
    "        'sku': np.repeat(filtered_warehouse_data['sku'].values, df_all_2.str.len()),\n",
    "        'date': np.concatenate(df_all_2.values)  # Convert DatetimeIndex to array for concatenation\n",
    "    })\n",
    "    df_all_2 = pd.merge(df_all_2, filtered_warehouse_data[['sku','valid_from_date', 'stock']], left_on=['sku', 'date'], right_on=['sku', 'valid_from_date'], how='left')\n",
    "    # ffil stock\n",
    "    df_all_2['stock'] = df_all_2['stock'].ffill()\n",
    "  #  df_all_2 = df_all_2.rename(columns={'stock':'warehouse stock'})\n",
    "    df_all_2 = df_all_2.drop(columns=['valid_from_date'])\n",
    "\n",
    "    df_all_2.to_parquet(\"df_all_store_{}.parquet\".format(store))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2.to_parquet(\"df_all_store_{}.parquet\".format(store))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2['sku_store'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data_sample[warehouse_data_sample['sku'] == '100657013000006']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_sku_stores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mbew_fashion[mbew_fashion['sku_store'] == '100090812000001,100']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_2[df_all_2['sku_store'] == '100090812000001,100']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warehouse_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_warehouse_df_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(100630490000005)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sku_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
