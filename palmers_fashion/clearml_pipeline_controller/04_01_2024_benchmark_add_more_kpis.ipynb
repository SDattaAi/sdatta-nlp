{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from typing import Optional\n",
    "import os\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "595d6c450a1a52d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3272364049f89539"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_warehouse_path = r'C:\\Users\\yotam\\SDatta\\fashion\\strategy_benchmark\\source_simulation\\31_12_2023\\df_all_store_VZ01.parquet'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22dd92f48a09ec42"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_warehouse = pd.read_parquet(df_warehouse_path)\n",
    "df_warehouse[\"sku\"]=df_warehouse[\"sku\"].astype(str)\n",
    "# filter sku that stock max is 0\n",
    "df_warehouse = df_warehouse[df_warehouse[\"stock\"]>0]\n",
    "df_warehouse = df_warehouse[~df_warehouse[\"sku\"].isin([\"100080385000001\",\"100080385000002\"])] \n",
    "# df_warehouse = df_warehouse[df_warehouse[\"sku\"]==\"100528128000008\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8780c0ac42a61364",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df_warehouse[df_warehouse[\"sku\"]==\"100633202000009\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fc3b409cc789f1d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "folder_of_stock_sales = r'C:\\Users\\yotam\\SDatta\\fashion\\strategy_benchmark\\source_simulation\\31_12_2023\\datasets_5'\n",
    "df_stock_sales = pd.DataFrame()\n",
    "for file in os.listdir(folder_of_stock_sales):\n",
    "    df_stock_sales = pd.concat([df_stock_sales, pd.read_parquet(os.path.join(folder_of_stock_sales, file))])\n",
    "df_stock_sales[\"sku\"]=df_stock_sales[\"sku\"].astype(str)\n",
    "df_stock_sales[\"store\"]=df_stock_sales[\"store\"].astype(str)\n",
    "df_stock_sales = df_stock_sales.drop(columns=[\"item\",\"sku_store\"])\n",
    "df_stock_sales = df_stock_sales[df_stock_sales[\"sku\"].isin(df_warehouse[\"sku\"].unique().tolist())]\n",
    "# df_stock_sales = df_stock_sales[df_stock_sales[\"sku\"]==\"100528128000008\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2245ceb1e8c03a0d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_warehouse = df_warehouse.rename(columns={\"stock\": \"warehouse_stock\"})\n",
    "df_stock_sales_temp = df_stock_sales\n",
    "df_warehouse_temp = df_warehouse"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8017ed0f3569bac",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assumption:\n",
    "\n",
    "##### 1. The time delivery ahead is 2 weeks (later we will change dynamically between stores for example 1 day - 14 days)\n",
    "##### 2. the prior sales distribution of stores taking from 1 year before the experiment (for example 2019 if the experiment is in 2020)\n",
    "##### 3. All the 126 stores going to be active in the optimization warehouse\n",
    "##### 4. Not all the time series of the stores are the same length, so there are some that starting earlier and some later (it depends on the store time shipping from the warehouse and also the time of the decision to start shipping to the store)\n",
    "##### 5. Discount over time:\n",
    "\n",
    "        5.1 after 20 weeks the discount is 0.8-0.85 % from the original price (the discount is the worst case for store because the store sales the product in the loss)\n",
    "\n",
    "##### 6. Removing worst stores over time:\n",
    "\n",
    "        6.1 6 weeks after store get the first delivery, if the store is in the bottom 10% of the stores from total stores, we remove it from the optimization warehouse\n",
    "        6.2 8 weeks after store get the first delivery, if the store is in the bottom 20% of the stores from total stores, we remove it from the optimization warehouse\n",
    "        6.3 12 weeks after store get the first delivery, if the store is in the bottom 30% of the stores from total stores, we remove it from the optimization warehouse\n",
    "        6.4 14 weeks after store get the first delivery, if the store is in the bottom 40% of the stores from total stores, we remove it from the optimization warehouse\n",
    "\n",
    "##### 7. There is no reordering to the warehouse what we have is what we have\n",
    "##### 8. If the stock in the warehouse is 0 we can move the stock of sku from other store to the store that need it but it is not optimal\n",
    "##### 10. The first allocation of the stock in store is given by the palmers (as 50% of the stock sku in the store they believe that the store can sell)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "167aec6ac1f32fe6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_stock_sales_temp[\"date\"] = pd.to_datetime(df_stock_sales_temp[\"date\"])\n",
    "df_warehouse_temp[\"date\"] = pd.to_datetime(df_warehouse_temp[\"date\"])\n",
    "df_stock_sales_temp = df_stock_sales_temp.sort_values(by=[\"date\", \"store\"])\n",
    "df_warehouse_temp = df_warehouse_temp.sort_values(by=[\"date\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c041ffd292d70902",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d67f93edc97e2cc2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load dict of deliveries from warehouse and arrivals to stores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c92a5779486bc1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "dict_arrivals_store_deliveries_path = r\"C:\\Users\\yotam\\SDatta\\fashion\\strategy_benchmark\\source_simulation\\31_12_2023\\date_to_store_deliveries_dict.json\"\n",
    "dict_deliveries_from_wharehouse_dict_path = r\"C:\\Users\\yotam\\SDatta\\fashion\\strategy_benchmark\\source_simulation\\31_12_2023\\deliveries_from_wharehouse_dict.json\"\n",
    "\n",
    "with open(dict_arrivals_store_deliveries_path) as json_file:\n",
    "    dict_arrivals_store_deliveries = json.load(json_file)\n",
    "\n",
    "with open(dict_deliveries_from_wharehouse_dict_path) as json_file:\n",
    "    dict_deliveries_from_wharehouse_dict = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aae3490f652c7e2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fix_dict_arrivals_stors ={84:173,\n",
    " 95:47,\n",
    " 91:225,\n",
    " 90:180,\n",
    " 73:181,\n",
    " 74:181,\n",
    " 99:106,\n",
    " 79:160,\n",
    " 81:186,\n",
    " 85:104,\n",
    " 88:104,\n",
    " 8:162,\n",
    " 96:43,\n",
    " 76:10,\n",
    " 89:57,82:106,7:173,69:26}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "538aa6423cf53c00",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for date,stores in dict_arrivals_store_deliveries.items():\n",
    "    for store_problem,store_same in fix_dict_arrivals_stors.items():\n",
    "        if store_same in stores:\n",
    "            stores.append(store_problem)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c2e232f0488276d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for date,stores in dict_deliveries_from_wharehouse_dict.items():\n",
    "    for store_problem,store_same in fix_dict_arrivals_stors.items():\n",
    "        if store_same in stores:\n",
    "            stores.append(store_problem)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae01ed9ccc51049b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unique_stores_in_2020 = set()\n",
    "for date,stores in dict_arrivals_store_deliveries.items():\n",
    "    extract_year = pd.to_datetime(date).year\n",
    "    if extract_year == 2020:\n",
    "        # show all the unique stores that arrive stock in 2020\n",
    "        unique_stores_in_2020.update(stores)\n",
    "                \n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "955403cf85103153",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# prepare dict of sales and dict of stocks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af8769d4d917d479"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def initialize_stocks(df_stock_sales, df_warehouse, stores, skus):\n",
    "    dict_stocks = {store: {sku: 0 for sku in skus} for store in stores + [\"VZ01\"]}\n",
    "    store_stock = df_stock_sales.groupby(['store', 'sku']).apply(lambda x: x[x['stock'] > 0]['stock'].iloc[0] if not x[x['stock'] > 0].empty else 0)\n",
    "    for (store, sku), stock in store_stock.items():\n",
    "        dict_stocks[store][sku] = stock\n",
    "    dict_sum_sku_stock = {sku: sum(dict_stocks[store][sku] for store in stores) for sku in skus}\n",
    "    for sku in skus:\n",
    "        # warehouse_stock = df_warehouse[(df_warehouse['sku'] == sku) & (df_warehouse[\"warehouse_stock\"].max() )]['warehouse_stock'].iloc[0]\n",
    "        # warehouse_stock take the max stock of the warehouse\n",
    "        warehouse_stock = df_warehouse[df_warehouse['sku'] == sku]['warehouse_stock'].max()\n",
    "        dict_stocks[\"VZ01\"][sku] = max(warehouse_stock - dict_sum_sku_stock.get(sku, 0), 0)  # Prevent negative stock\n",
    "    return dict_stocks\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61c5356006be92d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_dict_sales(df_stock_sales):\n",
    "    filtered_df = df_stock_sales[df_stock_sales['sales'] != 0]\n",
    "    grouped_df = filtered_df.groupby(['store', 'date', 'sku'])['sales'].sum().reset_index()\n",
    "    grouped_df['date'] = grouped_df['date'].dt.strftime('%Y-%m-%d')\n",
    "    dict_sales = {}\n",
    "    for _, row in grouped_df.iterrows():\n",
    "        store = row['store']\n",
    "        date = row['date']\n",
    "        sku = row['sku']\n",
    "        amount = row['sales']\n",
    "        if store not in dict_sales:\n",
    "            dict_sales[store] = {}\n",
    "        if date not in dict_sales[store]:\n",
    "            dict_sales[store][date] = []\n",
    "        dict_sales[store][date].append((sku, amount))\n",
    "    return dict_sales"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71a8d701e6b7aa25",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "skus_simulation = df_stock_sales_temp[\"sku\"].unique().tolist()\n",
    "stores_simulation = df_stock_sales_temp[\"store\"].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "488018ae3dfdf75f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dict_stocks = initialize_stocks( df_stock_sales_temp,df_warehouse_temp, stores_simulation, skus_simulation)\n",
    "sum([dict_stocks[store][sku] for store in dict_stocks for sku in dict_stocks[store] if store != \"VZ01\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "807a36bd9dbc1731",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for store in dict_stocks:\n",
    "    for sku in dict_stocks[store]:\n",
    "        if store == \"VZ01\":\n",
    "            print(sku)\n",
    "            print(dict_stocks[store][sku])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deb839f01b5246fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dict_sales = create_dict_sales(df_stock_sales_temp)\n",
    "# print(dict_stocks)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cdbe17c7b5bcf7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get the start and end dates of the palmers each store and sku"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "439ce4eb48907396"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_from_first_non_zero(group):\n",
    "    first_non_zero_index = group[group['stock_palmers'].ne(0)].index.min()\n",
    "    return group.loc[first_non_zero_index:]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64117d2463307a7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_to_last_non_zero(group):\n",
    "    group['date'] = pd.to_datetime(group['date'], format='%Y-%m-%d')\n",
    "    last_non_zero_date = group[group['stock_palmers'].ne(0)]['date'].max()\n",
    "    day_after_last_non_zero = last_non_zero_date + pd.Timedelta(days=1)\n",
    "    group = group[group['date'] <= day_after_last_non_zero]\n",
    "    group[\"date\"] = group[\"date\"].astype(str)\n",
    "    return group"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd607f79bd828982"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def filter_from_first_non_zero_warehouse(group):\n",
    "    first_non_zero_index = group[group['warehouse_stock'].ne(0)].index.min()\n",
    "    return group.loc[first_non_zero_index:]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc7a1e588e3cbfff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def filter_to_last_non_zero_wh(group):\n",
    "    group['date'] = pd.to_datetime(group['date'], format='%Y-%m-%d')\n",
    "    last_non_zero_date = group[group['warehouse_stock'].ne(0)]['date'].max()\n",
    "    day_after_last_non_zero = last_non_zero_date + pd.Timedelta(days=1)\n",
    "    group = group[group['date'] <= day_after_last_non_zero]\n",
    "    group[\"date\"] = group[\"date\"].astype(str)\n",
    "    return group"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "910b6d5722eecfad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def creat_dict_start_dates(df_palmers,df_warehouse):\n",
    "    \"\"\"\n",
    "    dic_start_dates[date] = [(sku, store),...]\n",
    "    \"\"\"\n",
    "    dict_start_dates = {}\n",
    "    df_palmers[\"date\"] = df_palmers[\"date\"].astype(str)\n",
    "    df_palmers = df_palmers.rename(columns={\"stock\": \"stock_palmers\"})\n",
    "    df_palmers = df_palmers[[\"stock_palmers\",\"store\",\"sku\",\"date\",\"sales\"]]\n",
    "    df_warehouse_grouped = df_warehouse.groupby(['sku'])\n",
    "    unique_groups = df_palmers.groupby(['store', 'sku'])\n",
    "    for (store, sku), group in unique_groups:\n",
    "        filtered_group_start = filter_from_first_non_zero(group)\n",
    "        if not filtered_group_start.empty:\n",
    "            start_date = filtered_group_start['date'].min()\n",
    "            if start_date not in dict_start_dates:\n",
    "                dict_start_dates[start_date] = []\n",
    "            dict_start_dates[start_date].append((sku, store))\n",
    "    # add the warehouse start dates with the function filter_from_first_non_zero_warehouse\n",
    "    for sku in df_warehouse_grouped:\n",
    "        filtered_group_start = filter_from_first_non_zero_warehouse(sku[1])\n",
    "        if not filtered_group_start.empty:\n",
    "            start_date = filtered_group_start['date'].min()\n",
    "            start_date = start_date.strftime('%Y-%m-%d')\n",
    "            if start_date not in dict_start_dates:\n",
    "                dict_start_dates[start_date] = []\n",
    "            dict_start_dates[start_date].append((sku[0], \"VZ01\"))\n",
    "        \n",
    "    return dict_start_dates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48d5e7799992f41a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dict_start_dates = creat_dict_start_dates(df_stock_sales_temp,df_warehouse_temp)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e68db95f5a1a910c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dict_start_dates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afaf86c82d11c9bc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def creat_dict_end_dates(df_palmers):\n",
    "    \"\"\"\n",
    "    dic_end_dates[date] = [sku1, sku2, ...]\n",
    "    \"\"\"\n",
    "    dict_end_dates = {}\n",
    "\n",
    "    # Convert dates to datetime objects for proper handling\n",
    "    df_palmers[\"date\"] = pd.to_datetime(df_palmers[\"date\"])\n",
    "\n",
    "    # Determine the last sale date for each SKU in df_palmers\n",
    "    for sku, group in df_palmers.groupby(['sku']):\n",
    "        last_sale_date = group[group['sales'].ne(0)]['date'].max()\n",
    "        if pd.notna(last_sale_date):\n",
    "            # The end date is the day after the last sale date\n",
    "            end_date = (last_sale_date + pd.Timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "            dict_end_dates.setdefault(end_date, []).append(sku)\n",
    "\n",
    "    return dict_end_dates\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6337f32840d46df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dict_end_dates = creat_dict_end_dates(df_stock_sales_temp)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8aa826732df56d9c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dict_end_dates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b32c239187346fda",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(dict_end_dates)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4add96f6769235bc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for dates in dict_start_dates:\n",
    "    for sku,store in dict_start_dates[dates]:\n",
    "        if store == \"VZ01\":\n",
    "            print(sku)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a723ebf6f5d8e77",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The simulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75b31d702f5b95b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def initialize_all_the_dicts(stores_simulation:list,skus_simulation:list, start_dates: dict, dict_stocks: dict) -> (dict,dict,dict,list,list,list,list):\n",
    "    \"\"\"\n",
    "    This function initialize all the dicts : AshlonStock, MissedSales, ActiveStores, current_stocks\n",
    "    Args: \n",
    "    --------\n",
    "    stores_simulation : list\n",
    "        list of stores to simulate\n",
    "    skus_simulation : list\n",
    "        list of skus to simulate\n",
    "    start_dates: dict\n",
    "        start_dates[date] = [(sku, store),...]\n",
    "        \n",
    "    -------\n",
    "    return:  AshlonStock, MissedSales, ActiveStores\n",
    "    \"\"\"\n",
    "    AshlonStock = {}\n",
    "    MissedSales = {} \n",
    "    ActiveStores = {}\n",
    "    current_stock = {}\n",
    "    accumulated_stocks = dict_stocks.copy()\n",
    "    accumulated_AshlonStock = []\n",
    "    accumulated_ActiveStores = []\n",
    "    start_dates_copy = start_dates.copy()\n",
    "    start_dates_copy = {pd.to_datetime(date): start_dates_copy[date] for date in start_dates_copy}\n",
    "    for sku in skus_simulation:\n",
    "        ActiveStores[sku] = {} \n",
    "    for store in stores_simulation:\n",
    "        store = str(store)\n",
    "        AshlonStock[store] = {}\n",
    "        MissedSales[store] = {}\n",
    "        ActiveStores[store] = {}\n",
    "        current_stock[store] = {}\n",
    "        for sku in skus_simulation:\n",
    "            MissedSales[store][sku] = 0\n",
    "            ActiveStores[sku][store] = 1\n",
    "    return  AshlonStock, MissedSales, ActiveStores, current_stock, accumulated_stocks, accumulated_AshlonStock, accumulated_ActiveStores\n",
    "\n",
    "def initialize_kpi_structures(stores_simulation: list ,skus_simulation: list) -> (dict,dict,dict,dict,dict,dict):\n",
    "    \"\"\"\n",
    "    This function initialize all the kpi dicts : d_wo_inv, d_wo_inv_wo_wh, Ex_i_s_r, avg_integral_diff, Ex_total_days_wo_inv\n",
    "    Args: \n",
    "    --------\n",
    "    stores_simulation : list\n",
    "        list of stores to simulate\n",
    "    skus_simulation : list\n",
    "        list of skus to simulate\n",
    "        \n",
    "    -------\n",
    "    return:  d_wo_inv, d_wo_inv_wo_wh, Ex_i_s_r, avg_integral_diff, Ex_total_days_wo_inv\n",
    "    \"\"\"\n",
    "    d_wo_inv = {}\n",
    "    d_wo_inv_wo_wh = {}\n",
    "    Ex_i_s_r = {}\n",
    "    avg_integral_diff = {}\n",
    "    Ex_total_days_wo_inv = {}\n",
    "    loose = {}\n",
    "    for sku in skus_simulation:\n",
    "        d_wo_inv[sku] = {}\n",
    "        d_wo_inv_wo_wh[sku] = {}\n",
    "        Ex_i_s_r[sku] = {}\n",
    "        avg_integral_diff[sku] = {}\n",
    "        Ex_total_days_wo_inv[sku] = {}\n",
    "        loose[sku] = 0\n",
    "        for store in stores_simulation:\n",
    "            d_wo_inv[sku][store] = 0\n",
    "            d_wo_inv_wo_wh[sku][store] = 0\n",
    "            Ex_i_s_r[sku][store] = {'len': 0, 'sum': 0}\n",
    "            avg_integral_diff[sku][store] = {'len': 0, 'sum': 0}\n",
    "            Ex_total_days_wo_inv[sku][store] = {'len': 0, 'sum': 0}\n",
    "    \n",
    "    return d_wo_inv, d_wo_inv_wo_wh, Ex_i_s_r, avg_integral_diff, Ex_total_days_wo_inv, loose"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d9a4971a4f2bd0e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def receive_stock(dict_stocks: dict, AshlonStock: dict, current_stores_arrivals_stock: list, date: str) -> (dict,dict):\n",
    "    \"\"\"\n",
    "    This function receive stock and update AshlonStock for the current stores that arrive stock today .\n",
    "    description:\n",
    "    1. update dict_stocks by the stock that arrive today\n",
    "    2. update AshlonStock by the stock that arrive today\n",
    "    3. delete the date from AshlonStock\n",
    "     Args: \n",
    "    --------\n",
    "    dict_stocks: dict\n",
    "        dict_stocks[store][sku] = amount\n",
    "    AshlonStock: dict\n",
    "        AshlonStock[store][date] = (sku, amount)\n",
    "    current_stores_arrivals_stock: list\n",
    "        list of stores that arrive stock today\n",
    "    date: str\n",
    "        date of the simulation\n",
    "    -------\n",
    "    return: dict_stocks, AshlonStock\n",
    "    \"\"\"\n",
    "    for store in current_stores_arrivals_stock:\n",
    "        store = str(store)\n",
    "        if store not in dict_stocks:\n",
    "            continue\n",
    "        if date not in AshlonStock[store] :\n",
    "            continue\n",
    "            \n",
    "        if date in AshlonStock[store]:\n",
    "            for delivery in AshlonStock[store][date]:\n",
    "                sku, amount = delivery\n",
    "                if sku in dict_stocks[store]:\n",
    "                    dict_stocks[store][sku] += amount\n",
    "                else:\n",
    "                    dict_stocks[store][sku] = amount\n",
    "            del AshlonStock[store][date]\n",
    "    return dict_stocks, AshlonStock   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "678f2fc7276a6d23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_stocks_by_sales(dict_stocks: dict,dict_sales: dict,MissedSales: dict,date: str) -> (dict,dict):\n",
    "    \"\"\"\n",
    "    This function update stocks by sales and update MissedSales by the following description:\n",
    "        1. check if the stock is enough for the sales\n",
    "        2. if the stock is enough for the sales update the stock\n",
    "        3. if the stock is not enough for the sales update the MissedSales\n",
    "    Args:\n",
    "    --------\n",
    "    dict_stocks: dict\n",
    "        dict_stocks[store][sku] = amount\n",
    "    dict_sales: dict\n",
    "        dict_sales[store][date] = (sku, amount)\n",
    "    MissedSales: dict\n",
    "        MissedSales[store][date] = (sku, amount)\n",
    "    -------\n",
    "    return: dict_stocks, MissedSales\n",
    "    \"\"\"\n",
    "    for store in dict_sales:\n",
    "        store = str(store)\n",
    "        if store not in dict_stocks:\n",
    "            continue\n",
    "        if date not in dict_sales[store] :\n",
    "            continue\n",
    "        for sale in dict_sales[store][date]:\n",
    "            sku, amount = sale\n",
    "            if sku not in dict_stocks[store]:\n",
    "                continue\n",
    "            if dict_stocks[store][sku] >= amount:\n",
    "                dict_stocks[store][sku] -= amount\n",
    "            else:\n",
    "                MissedSales[store][sku] += amount - dict_stocks[store][sku]\n",
    "                dict_stocks[store][sku] = 0\n",
    "    \n",
    "        # del dict_sales[store][date]\n",
    "    return dict_stocks, MissedSales"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41ab47fa545f79c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_active_stores(ActiveStores: dict,dict_stocks: dict) -> dict:\n",
    "    \"\"\"\n",
    "    This function update ActiveStores (note: update by hard data from the past from outside the simulation)\n",
    "    \n",
    "    \n",
    "    assumption for now: all the stores are active\n",
    "    for later: we will need to decide which stores are active and which are not by timeline interval rule\n",
    "    Args:\n",
    "    --------\n",
    "    ActiveStores: dict\n",
    "        ActiveStores[store] = 1/0\n",
    "    dict_stocks: dict\n",
    "        dict_stocks[store][sku] = amount\n",
    "    -------\n",
    "    return: ActiveStores\n",
    "    \"\"\"\n",
    "    return ActiveStores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ba11c3cd22ac0e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def extract_last_sale_for_sku(dict_sales: dict,store: str,sku: str,current_date: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    This function extract the last date and sku from dict_sales\n",
    "    Args:\n",
    "    --------\n",
    "    dict_sales: dict\n",
    "        dict_sales[store][date] = (sku, amount)\n",
    "    store: str\n",
    "        store id\n",
    "    -------\n",
    "    return: last_date, sku\n",
    "    \"\"\"\n",
    "    for date in dict_sales[store].keys():\n",
    "        if current_date <= date:\n",
    "            continue\n",
    "        for sale in dict_sales[store][date]:\n",
    "            sale_sku, amount = sale\n",
    "            if sale_sku == sku:\n",
    "                return amount\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60cd8db0d6a3770e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_AshlonStock_waerhouse(potential_stock_order_from_warehouse:int,dict_stocks:dict,AshlonStock:dict, accumulated_stocks: dict,sku:str,store:str,date:str):\n",
    "    \"\"\"\n",
    "    This function update the AshlonStock and dict_stocks by the following description:\n",
    "    1. check if the potential_stock_order_from_warehouse is positive and the stock in the warehouse is enough for the order\n",
    "    2. update the stock in the warehouse\n",
    "    3. update the AshlonStock for the future date (2 days from the current date)\n",
    "    Args:\n",
    "    --------\n",
    "    potential_stock_order_from_warehouse: int\n",
    "        amount of the last sale - the stock of the store\n",
    "    dict_stocks: dict\n",
    "        dict_stocks[store][sku] = amount\n",
    "    AshlonStock: dict\n",
    "        AshlonStock[store][date] = (sku, amount)\n",
    "    accumulated_stocks: dict\n",
    "        accumulated_stocks[store][sku] = amount\n",
    "    sku: str\n",
    "        sku id\n",
    "    store: str\n",
    "        store id\n",
    "    date: str\n",
    "        date of the simulation\n",
    "    -------\n",
    "    return: dict_stocks, AshlonStock\n",
    "    \"\"\"\n",
    "    if potential_stock_order_from_warehouse <= dict_stocks[\"VZ01\"][sku] and potential_stock_order_from_warehouse > 0:\n",
    "        store = str(store)\n",
    "        dict_stocks[\"VZ01\"][sku] -= potential_stock_order_from_warehouse\n",
    "        two_days_from_current_date = pd.to_datetime(date) + pd.Timedelta(days=2)\n",
    "        two_days_from_current_date_str = two_days_from_current_date.strftime('%Y-%m-%d')\n",
    "        AshlonStock[store][two_days_from_current_date_str] = AshlonStock[store].get(two_days_from_current_date_str, []) + [(sku, potential_stock_order_from_warehouse)]\n",
    "        accumulated_stocks[store][sku] += potential_stock_order_from_warehouse\n",
    "    return dict_stocks,AshlonStock,accumulated_stocks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcf7209c8112f8da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_current_stock_with_new_sku(current_stock: dict,start_dates: dict, date: str, dict_stocks: dict, Ex_total_days_wo_inv: dict, Ex_i_s_r: dict, avg_integral_diff: dict) -> tuple[dict, dict, dict, dict]:\n",
    "    \"\"\"\n",
    "    This function update current_stock with new sku\n",
    "    Args:\n",
    "    --------\n",
    "    current_stock: dict\n",
    "        current_stock[store][sku] = amount\n",
    "    start_dates: dict\n",
    "        start_dates[date] = [(sku, store),...]\n",
    "    date: str\n",
    "        date of the simulation\n",
    "    -------\n",
    "    return: current_stock, Ex_tottal_days_wo_inv, Ex_i_s_r, avg_integral_diff\n",
    "    \"\"\"\n",
    "    for data in start_dates[date]:\n",
    "        sku, store = data\n",
    "        current_stock[store][sku] = dict_stocks[store][sku]\n",
    "        Ex_total_days_wo_inv[sku][store] = {'len': 0, 'sum': 0}\n",
    "        Ex_i_s_r[sku][store] = {'len': 0, 'sum': 0}\n",
    "        avg_integral_diff[sku][store] = {'len': 0, 'sum': 0}\n",
    "    return current_stock, Ex_total_days_wo_inv, Ex_i_s_r, avg_integral_diff"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9b3b25041f6e91b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_current_stock_with_kill_sku(current_stock: dict, end_dates: dict, date: str, loose: dict, dict_stocks: dict, ashelon_stock: dict) -> tuple[dict, dict, dict]:\n",
    "    \"\"\"\n",
    "    This function update current_stock with kill sku\n",
    "    Args:\n",
    "    --------\n",
    "    current_stock: dict\n",
    "        current_stock[store][sku] = amount\n",
    "    end_dates: dict\n",
    "        end_dates[date] = [(sku),...]\n",
    "    date: str\n",
    "        date of the simulation\n",
    "    loose: dict\n",
    "        loose[sku] = percent of loose\n",
    "    -------\n",
    "    return: current_stock, loose\n",
    "    \n",
    "    Note:\n",
    "        1. loose is the percent of the stock that we have not sold\n",
    "    \"\"\"\n",
    "    date_datetime = pd.to_datetime(date)\n",
    "    for sku in end_dates[date]:\n",
    "        tempo_sku_total_stock = 0\n",
    "        for store in current_stock:\n",
    "            if sku in current_stock[store]:\n",
    "                loose[sku] += current_stock[store][sku]\n",
    "                del current_stock[store][sku]\n",
    "            if store in dict_stocks and sku in dict_stocks.get(store, {}):\n",
    "                tempo_sku_total_stock += dict_stocks[store][sku]\n",
    "            for date_str in pd.date_range(date_datetime, date_datetime + pd.Timedelta(days=2), freq=\"D\"):\n",
    "                date_str = date_str.strftime('%Y-%m-%d')\n",
    "                if store in ashelon_stock and date_str in ashelon_stock.get(store, {}) and sku in ashelon_stock[store].get(date_str, {}):\n",
    "                    sku, amount = ashelon_stock[store][date_str]\n",
    "                    loose[sku] += amount\n",
    "                    del ashelon_stock[store][date_str]\n",
    "        if tempo_sku_total_stock == 0:\n",
    "            raise ValueError(f\"initial stock for sku {sku} is 0\")\n",
    "        loose[sku] = loose[sku] / tempo_sku_total_stock\n",
    "    return current_stock, loose, ashelon_stock\n",
    "\n",
    "def update_kpi_wo_inv(d_wo_inv: dict, d_wo_inv_wo_wh: dict, current_stock: dict, Ex_total_days_wo_inv: dict) -> tuple[dict, dict, dict]:\n",
    "    \"\"\"\n",
    "    This function update kpi dicts : d_wo_inv, d_wo_inv_wo_wh, Ex_total_days_wo_inv\n",
    "    Args:\n",
    "    --------\n",
    "    d_wo_inv: dict\n",
    "        d_wo_inv[sku][store] = amount\n",
    "    d_wo_inv_wo_wh: dict\n",
    "        d_wo_inv_wo_wh[sku][store] = amount\n",
    "    current_stock: dict\n",
    "        current_stock[store][sku] = amount\n",
    "\n",
    "    -------\n",
    "    return: d_wo_inv, d_wo_inv_wo_wh, Ex_total_days_wo_inv\n",
    "    \"\"\"\n",
    "    for store in current_stock:\n",
    "        for sku in current_stock[store]:\n",
    "            if current_stock[store][sku] == 0:\n",
    "                d_wo_inv[sku][store] += 1\n",
    "                Ex_total_days_wo_inv[sku][store]['len'] += 1\n",
    "                Ex_total_days_wo_inv[sku][store]['sum'] += d_wo_inv[sku][store]/Ex_total_days_wo_inv[sku][store]['len']\n",
    "                if store != \"VZ01\" and current_stock[store][sku] == 0:\n",
    "                    d_wo_inv_wo_wh[sku][store] += 1\n",
    "            else:\n",
    "                print(f\"store: {store}, sku: {sku}\")\n",
    "                print(\"current_stock[store][sku]: \", current_stock[store][sku])\n",
    "                Ex_total_days_wo_inv[sku][store]['len'] += 1\n",
    "    return d_wo_inv, d_wo_inv_wo_wh, Ex_total_days_wo_inv\n",
    "\n",
    "def update_info_for_kpi(accumulated_stocks: dict,current_stock: dict, Ex_i_s_r: dict, avg_integral_diff: dict, margin_ratio: int = 3) -> tuple[dict, dict]:\n",
    "    \"\"\"\n",
    "    This function update kpi dicts : Ex_i_s_r, avg_integral_diff\n",
    "    Args:\n",
    "    --------\n",
    "    accumulated_stocks: dict\n",
    "        accumulated_stocks[store][sku] = amount\n",
    "    current_stock: dict\n",
    "        current_stock[store][sku] = amount\n",
    "\n",
    "    -------\n",
    "    return: Ex_i_s_r, avg_integral_diff\n",
    "    \"\"\"\n",
    "    for store in current_stock:\n",
    "        total_stock, total_sales = 0, 0\n",
    "        if store == \"VZ01\":\n",
    "            continue\n",
    "        for sku in current_stock[store]:\n",
    "            total_stock += accumulated_stocks[store][sku]\n",
    "            total_sales += accumulated_stocks[store][sku] - current_stock[store][sku]\n",
    "            if total_stock == 0:\n",
    "                Ex_i_s_r[sku][store]['len'] += 1\n",
    "                Ex_i_s_r[sku][store]['sum'] += 0\n",
    "            else:\n",
    "                Ex_i_s_r[sku][store]['len'] += 1\n",
    "                Ex_i_s_r[sku][store]['sum'] += total_sales / total_stock\n",
    "            avg_integral_diff[sku][store]['len'] += 1\n",
    "            avg_integral_diff[sku][store]['sum'] += current_stock[store][sku] - 1 if current_stock[store][sku] > 0 else margin_ratio\n",
    "        for sku in current_stock['VZ01']:\n",
    "            total_stock = np.sum([accumulated_stocks[store][sku] for store in current_stock])\n",
    "            total_sales = total_stock - current_stock['VZ01'][sku]\n",
    "            if total_stock == 0:\n",
    "                raise ValueError(f\"total initialized stock in all stores for sku {sku} is 0\") \n",
    "            else:\n",
    "                Ex_i_s_r[sku]['VZ01']['len'] += 1\n",
    "                Ex_i_s_r[sku]['VZ01']['sum'] += total_sales / total_stock\n",
    "    return Ex_i_s_r, avg_integral_diff"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "705786700b3789d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def kill_and_save_results(accumulated_stocks: dict, d_wo_inv: dict, d_wo_inv_wo_wh: dict, Ex_i_s_r: dict, avg_integral_diff: dict, Ex_total_days_wo_inv: dict, loose: dict, date: str, end_dates: dict, MissedSales: dict, base_path: str = r'C:\\Users\\yotam\\SDatta\\fashion\\strategy_benchmark\\source_simulation\\07_01_2024', simulation_name: str = 'run1', lamda: float = 0.1) -> tuple[dict, dict, dict, dict, dict, dict, dict, dict]:\n",
    "    \"\"\"\n",
    "    This function kill and save results\n",
    "    Args:\n",
    "    --------\n",
    "    d_wo_inv: dict\n",
    "        d_wo_inv[sku][store] = amount\n",
    "    d_wo_inv_wo_wh: dict\n",
    "        d_wo_inv_wo_wh[sku][store] = amount\n",
    "    Ex_i_s_r: dict\n",
    "        Ex_i_s_r[sku][store] = amount\n",
    "    avg_integral_diff: dict\n",
    "        avg_integral_diff[sku][store] = amount\n",
    "    Ex_total_days_wo_inv: dict\n",
    "        Ex_total_days_wo_inv[sku][store] = amount\n",
    "    loose: dict\n",
    "        loose[sku] = percent of loose\n",
    "    date: str\n",
    "        date of the simulation\n",
    "    strategy_names: str\n",
    "        name of the strategy to apply\n",
    "    end_dates: dict\n",
    "        end_dates[date] = [(sku),...]\n",
    "    MissedSales: dict\n",
    "        MissedSales[store][date] = (sku, amount)\n",
    "    -------\n",
    "    return: d_wo_inv, d_wo_inv_wo_wh, Ex_i_s_r, avg_integral_diff, Ex_total_days_wo_inv, loose, MissedSales\n",
    "    \"\"\"\n",
    "    if date not in end_dates:\n",
    "        return accumulated_stocks, d_wo_inv, d_wo_inv_wo_wh, Ex_i_s_r, avg_integral_diff, Ex_total_days_wo_inv, loose, MissedSales\n",
    "    final_kpi_res = {}\n",
    "    simulation_dir = os.path.join(base_path, simulation_name)\n",
    "    if not os.path.exists(simulation_dir):\n",
    "        os.makedirs(simulation_dir)\n",
    "    for sku in end_dates[date]:\n",
    "        for store in accumulated_stocks:\n",
    "            if sku in accumulated_stocks[store]:\n",
    "                lose =d_wo_inv[sku][\"VZ01\"]*(np.exp(lamda*loose[sku])-1), loose[sku] if store == \"VZ01\" else None\n",
    "                avg_integral_diff_sum_divde_avg_integral_diff=  avg_integral_diff[sku][store][\"sum\"]/avg_integral_diff[sku][store][\"len\"] if avg_integral_diff[sku][store][\"len\"] != 0 else None\n",
    "                Ex_total_days_wo_inv_sum_divde_Ex_total_days_wo_inv = Ex_total_days_wo_inv[sku][store][\"sum\"]/Ex_total_days_wo_inv[sku][store][\"len\"] if Ex_total_days_wo_inv[sku][store][\"len\"] != 0 else None\n",
    "                Ex_i_s_r_sum_divde_Ex_i_s_r = Ex_i_s_r[sku][store][\"sum\"]/Ex_i_s_r[sku][store][\"len\"] if Ex_i_s_r[sku][store][\"len\"] != 0 else None\n",
    "                final_kpi_res[f'{sku}_{store}'] = {f'days without stock in {sku, store}: {d_wo_inv[sku][store]}',\n",
    "                                 f'days without stock in {sku, store} without warehouse: {d_wo_inv_wo_wh[sku][store]}',\n",
    "                                    f'expected value inventory sales ratio in {sku, store}: {Ex_i_s_r_sum_divde_Ex_i_s_r}',\n",
    "                                    f'average integral difference in {sku, store}: {avg_integral_diff_sum_divde_avg_integral_diff}',\n",
    "                                    f'expected value total days without inventory in {sku, store}: {Ex_total_days_wo_inv_sum_divde_Ex_total_days_wo_inv}',\n",
    "                                    f'loose, lose ratio in {sku} {lose}',\n",
    "                                    f'missed sales in {sku, store}: {MissedSales[store][sku]}',\n",
    "                                    f'accumulated stock in {sku, store}: {accumulated_stocks[store][sku]}'}\n",
    "                \n",
    "                file_path = os.path.join(simulation_dir, f'{sku}_{store}.pkl')\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    pickle.dump(final_kpi_res[f'{sku}_{store}'], f)\n",
    "                del accumulated_stocks[store][sku], d_wo_inv[sku][store], d_wo_inv_wo_wh[sku][store], Ex_i_s_r[sku][store], avg_integral_diff[sku][store], Ex_total_days_wo_inv[sku][store], MissedSales[store][sku]   \n",
    "        del loose[sku]\n",
    "    return accumulated_stocks, d_wo_inv, d_wo_inv_wo_wh, Ex_i_s_r, avg_integral_diff, Ex_total_days_wo_inv, loose, MissedSales"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ec47088f5460d4d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def apply_strategy_naive_bayes(dict_stocks: dict, AshlonStock: dict, ActiveStores: dict, current_stores_replenished: list, dict_sales: dict, accumulated_stocks: dict, date: str,store_traveling_time_dict: dict = None) -> (dict, dict):\n",
    "    \"\"\"\n",
    "    This function apply strategy and update dict_stocks, AshlonStock.\n",
    "    The strategy is naive bayes:\n",
    "    1. for every store that can be replenished from the warehouse\n",
    "    2. for every sku in the store\n",
    "    3. check if the store sold the last sale of the sku\n",
    "    4. if the store sold the last sale of the sku\n",
    "    5. add 1 to the last sale of the sku\n",
    "    6. caculate the potential_stock_order_from_warehouse = amount of the last sale - the stock of the store\n",
    "    7. if the potential_stock_order_from_warehouse is positive and the stock in the warehouse is enough for the order\n",
    "    8. update the stock in the warehouse\n",
    "    9. update the AshlonStock\n",
    "\n",
    "    Args:\n",
    "    --------\n",
    "    dict_stocks: dict\n",
    "        dict_stocks[store][sku] = amount\n",
    "    AshlonStock: dict\n",
    "        AshlonStock[store][date] = (sku, amount)\n",
    "    ActiveStores: dict\n",
    "        ActiveStores[store] = 1/0\n",
    "    current_stores_replenished: list\n",
    "        list of stores that can be replenished from the warehouse\n",
    "    dict_sales: dict\n",
    "        dict_sales[store][date] = (sku, amount)\n",
    "    accumulated_stocks: dict\n",
    "        accumulated_stocks[store][sku] = amount\n",
    "    date: str\n",
    "        date of the simulation\n",
    "    store_traveling_time_dict: dict\n",
    "        store_traveling_time_dict[store] = traveling_time\n",
    "    -------\n",
    "    return: dict_stocks, AshlonStock\n",
    "    \"\"\"\n",
    "    for store in current_stores_replenished:\n",
    "        store = str(store)\n",
    "        if store not in dict_stocks:\n",
    "            continue\n",
    "        for sku in dict_stocks[store].keys():\n",
    "            if ActiveStores[sku][store] == 0:\n",
    "                continue\n",
    "            amount_last_sale = extract_last_sale_for_sku(dict_sales, store,sku,date) + 1 if extract_last_sale_for_sku(dict_sales, store,sku,date) is not None else None\n",
    "            if amount_last_sale is None:\n",
    "                continue\n",
    "            potential_stock_order_from_warehouse = amount_last_sale - dict_stocks[store][sku]\n",
    "            dict_stocks,AshlonStock,accumulated_stocks = update_AshlonStock_waerhouse(potential_stock_order_from_warehouse,dict_stocks,AshlonStock,accumulated_stocks,sku,store,date)\n",
    "    return dict_stocks, AshlonStock, accumulated_stocks        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94601330838b13de",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def main_simulation(dict_deliveries_from_warehouse: dict,dict_arrivals_store_deliveries : dict,stores_simulation : list,skus_simulation : list,dict_sales : dict, dict_stocks: dict, start_dates: dict, end_dates: dict, strategy_names:str=\"naive_bayes\") -> None:\n",
    "    \"\"\"\n",
    "    This function is the main simulation function by the next steps:\n",
    "    0. initialize all the dicts : AshlonStock, MissedSales, ActiveStores, current_stocks\n",
    "    1. start queue\n",
    "    2. Check which stores accept inventory today: 2.1 check for new sku in the store or sku to kill\n",
    "                                                  2.2 check for incoming inventory\n",
    "    3. receive stock and update AshlonStock\n",
    "    4. update stocks by sales and update MissedSales\n",
    "    5. update ActiveStores (note: update by hard data from the past from outside the simulation)\n",
    "    6. current stores that can be replenished from dict_deliveries_from_warehouse\n",
    "    7. apply strategy and update current_stocks, AshlonStock\n",
    "    8. save results\n",
    "    9. end queue\n",
    "    \n",
    "    Args: \n",
    "    --------\n",
    "    dict_deliveries_from_warehouse: dict\n",
    "        dict_deliveries_from_warehouse[date] = [store1,store2,...]\n",
    "    dict_arrivals_store_deliveries : dict\n",
    "        dict_arrivals_store_deliveries[date] = [store1,store2,...]\n",
    "    stores_simulation : list\n",
    "        list of stores to simulate\n",
    "    skus_simulation : list\n",
    "        list of skus to simulate\n",
    "    dict_sales : dict\n",
    "        dict_sales[store][date] = (sku, amount)\n",
    "    dict_stocks: dict\n",
    "        dict_stocks[store][sku] = amount\n",
    "    start_date : str\n",
    "        start date of the simulation\n",
    "    end_date : str\n",
    "        end date of the simulation\n",
    "    start_dates: dict\n",
    "        start_dates[date] = [(sku, store),...]\n",
    "    end_dates: dict\n",
    "        end_dates[date] = [(sku),...]\n",
    "    strategy_names: str\n",
    "        name of the strategy to apply (Default: \"naive_bayes\")\n",
    "        \n",
    "    -------\n",
    "    return: None\n",
    "    \n",
    "    Note:\n",
    "        1. All constants are in the strategy\n",
    "        2. The simulation is by days (every queue is a day)\n",
    "        3. AshlonStock[store][date] = (sku, amount)\n",
    "        4. MissedSales[store][date] = (sku, amount)\n",
    "        5. ActiveStores[store] = 1/0\n",
    "    \"\"\"\n",
    "    AshlonStock, MissedSales, ActiveStores, current_stock, accumulated_stocks, accumulated_AshlonStock, accumulated_ActiveStores = initialize_all_the_dicts(stores_simulation,skus_simulation, start_dates, dict_stocks)\n",
    "    d_wo_inv, d_wo_inv_wo_wh, Ex_i_s_r, avg_integral_diff, Ex_total_days_wo_inv, loose = initialize_kpi_structures(stores_simulation,skus_simulation) \n",
    "    start_dates_copy = start_dates.copy()\n",
    "    start_dates_copy = {pd.to_datetime(date): start_dates_copy[date] for date in start_dates_copy}\n",
    "    min_start_date_copy = min(start_dates_copy.keys()).strftime('%Y-%m-%d')\n",
    "    dict_end_dates_copy = end_dates.copy()\n",
    "    dict_end_dates_copy = {pd.to_datetime(date): dict_end_dates_copy[date] for date in dict_end_dates_copy}\n",
    "    end_date = max(dict_end_dates_copy.keys()).strftime('%Y-%m-%d')\n",
    "    for date in pd.date_range(min_start_date_copy,end_date,freq=\"D\"):\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        print(f\"Processing date {date_str}\")\n",
    "        if date_str in start_dates.keys():\n",
    "            current_stock, Ex_total_days_wo_inv, Ex_i_s_r, avg_integral_diff = update_current_stock_with_new_sku(current_stock, start_dates, date_str, dict_stocks, Ex_total_days_wo_inv,  Ex_i_s_r, avg_integral_diff )\n",
    "        if date_str in end_dates.keys():\n",
    "            current_stock, loose,AshlonStock = update_current_stock_with_kill_sku(current_stock,end_dates,date_str, loose, dict_stocks, AshlonStock) \n",
    "        if date_str in dict_arrivals_store_deliveries:\n",
    "            current_stores_arrivals_stock = dict_arrivals_store_deliveries[date_str]\n",
    "            current_stock, AshlonStock = receive_stock(current_stock,AshlonStock,current_stores_arrivals_stock,date_str) \n",
    "        d_wo_inv, d_wo_inv_wo_wh, Ex_total_days_wo_inv = update_kpi_wo_inv(d_wo_inv, d_wo_inv_wo_wh, current_stock, Ex_total_days_wo_inv)\n",
    "        current_stock, MissedSales = update_stocks_by_sales(current_stock,dict_sales,MissedSales,date_str)\n",
    "        ActiveStores = update_active_stores(ActiveStores,current_stock)\n",
    "        if date_str in dict_deliveries_from_warehouse:\n",
    "            current_stores_replenished = dict_deliveries_from_warehouse[date_str]\n",
    "            current_stock, AshlonStock, accumulated_stocks = apply_strategy_naive_bayes(current_stock,AshlonStock,ActiveStores,current_stores_replenished,dict_sales, accumulated_stocks,date_str)\n",
    "        Ex_i_s_r, avg_integral_diff = update_info_for_kpi(accumulated_stocks,current_stock,Ex_i_s_r,avg_integral_diff) \n",
    "        accumulated_stocks, d_wo_inv, d_wo_inv_wo_wh, Ex_i_s_r, avg_integral_diff, Ex_total_days_wo_inv, loose, MissedSales  = kill_and_save_results(accumulated_stocks, d_wo_inv, d_wo_inv_wo_wh, Ex_i_s_r, avg_integral_diff, Ex_total_days_wo_inv, loose, date_str, end_dates, MissedSales)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9156134533ee1e93",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "main_simulation(dict_deliveries_from_wharehouse_dict,dict_arrivals_store_deliveries,list(stores_simulation)+[\"VZ01\"],skus_simulation,dict_sales,dict_stocks,dict_start_dates,dict_end_dates)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d640e901b87e1f1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dict_stocks[\"100\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "198fbcd854869007",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dict_stocks[\"4133\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6db3520080c1f474",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def save_results( accumulated_AshlonStock: list,error_metrics:pd.DataFrame , base_output_dir: str=r\"C:\\Users\\yotam\\SDatta\\fashion\\simulation_res\\simulation_results_benchmark\") -> None:\n",
    "#     \"\"\"\n",
    "#     This function save results to csv\n",
    "#     Args:\n",
    "#     --------\n",
    "#     dict_stocks: dict\n",
    "#         dict_stocks[store][sku] = amount\n",
    "#     AshlonStock: dict\n",
    "#         AshlonStock[store][date] = (sku, amount)\n",
    "#     MissedSales: dict\n",
    "#         MissedSales[store][date] = (sku, amount)\n",
    "#     ActiveStores: dict\n",
    "#         ActiveStores[store] = 1/0\n",
    "#     -------\n",
    "#     return: None\n",
    "#     \"\"\"\n",
    "#     experiment_number = 1\n",
    "#     output_dir = os.path.join(base_output_dir, f\"experiment_{experiment_number}\")\n",
    "#     while os.path.exists(output_dir):\n",
    "#         experiment_number += 1\n",
    "#         output_dir = os.path.join(base_output_dir, f\"experiment_{experiment_number}\")\n",
    "# \n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     df_AshlonStock = pd.DataFrame(accumulated_AshlonStock)\n",
    "#     \n",
    "#     df_AshlonStock.to_csv(os.path.join(output_dir, \"AshlonStock.csv\"), index=False)\n",
    "#     error_metrics.to_csv(os.path.join(output_dir, \"error_metrics.csv\"), index=False)\n",
    "#     print(f\"Saved final simulation results in {output_dir}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3344f4a053459ce8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def apply_strategy(dict_stocks: dict, AshlonStock: dict, ActiveStores: dict, current_stores_replenished: list, dict_sales: dict, date: str) -> (dict, dict):\n",
    "#     \"\"\"\n",
    "#     Apply strategy and update dict_stocks, AshlonStock\n",
    "#     \"\"\"\n",
    "#     pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c15bed92a5f89da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def update_accumulated(accumulated_stocks, accumulated_AshlonStock, accumulated_MissedSales, dict_stocks, AshlonStock, MissedSales, date):\n",
    "#     pd_date = pd.to_datetime(date)\n",
    "#     accumulated_stocks.extend([\n",
    "#         {'store': store, 'sku': sku, 'date': date, 'stock': int(amount)}\n",
    "#         for store in dict_stocks \n",
    "#         for sku, amount in dict_stocks[store].items()\n",
    "#     ])\n",
    "# \n",
    "#     \n",
    "#     accumulated_AshlonStock.extend([{**{'store': store, 'date': date}, **{'stock': amount}} for store in AshlonStock for  amount in AshlonStock[store].items()])\n",
    "#     \n",
    "#     accumulated_MissedSales.extend([\n",
    "#         {'store': store, 'sku': sku, 'date': date, 'amount_miss_sales': int(amount)}\n",
    "#         for store in MissedSales \n",
    "#         for sku, amount in MissedSales[store].items()\n",
    "#     ])\n",
    "#     return accumulated_stocks, accumulated_AshlonStock, accumulated_MissedSales\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e9cc2e61ccde70e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def filter_from_first_non_zero(group):\n",
    "#     first_non_zero_index = group[group['stock_palmers'].ne(0)].index.min()\n",
    "#     return group.loc[first_non_zero_index:]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "943412695cab13f6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def filter_to_last_non_zero(group):\n",
    "#     group['date'] = pd.to_datetime(group['date'], format='%Y-%m-%d')\n",
    "#     last_non_zero_date = group[group['stock_palmers'].ne(0)]['date'].max()\n",
    "#     day_after_last_non_zero = last_non_zero_date + pd.Timedelta(days=1)\n",
    "#     group = group[group['date'] <= day_after_last_non_zero]\n",
    "#     group[\"date\"] = group[\"date\"].astype(str)\n",
    "#     return group"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6d4737acd7959da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def process_groups_without_apply(df_palmers):\n",
    "#     unique_groups = df_palmers.groupby(['store', 'sku'])\n",
    "#     result_frames = []\n",
    "#     for name, group in unique_groups:\n",
    "#         filtered_group = filter_to_last_non_zero(group)\n",
    "#         result_frames.append(filtered_group)\n",
    "#     return pd.concat(result_frames)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1769f8cab2b0abf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def filter_dates_inner_with_palmers(accumulated_stocks:list,df_palmers:pd.DataFrame,strategy_names:str,accumulated_MissedSales:list) -> pd.DataFrame:\n",
    "#     df_stocks = pd.DataFrame(accumulated_stocks)\n",
    "#     df_stocks = df_stocks.rename(columns={\"stock\": f\"stock_{strategy_names}\"})\n",
    "#     df_miss_sales = pd.DataFrame(accumulated_MissedSales)\n",
    "#     df_palmers[\"date\"] = df_palmers[\"date\"].astype(str)\n",
    "#     df_palmers = df_palmers.rename(columns={\"stock\": \"stock_palmers\"})\n",
    "#     df_palmers = df_palmers[[\"stock_palmers\",\"store\",\"sku\",\"date\",\"sales\"]]\n",
    "#     df_palmers_start_from_no_zero = df_palmers.groupby(['store', 'sku'], group_keys=False).apply(filter_from_first_non_zero)\n",
    "#     df_palmers_end_from_no_zero = process_groups_without_apply(df_palmers_start_from_no_zero)\n",
    "#     df_stocks_inner = df_stocks.merge(df_palmers_end_from_no_zero,how=\"right\",on=[\"store\",\"sku\",\"date\"])\n",
    "#     df_compare = df_miss_sales.merge(df_stocks_inner,how=\"right\",on=[\"store\",\"sku\",\"date\"])\n",
    "#     return df_compare"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "830d7e9dcd71be1e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def compute_error_metrics(df_all_clean_after_merge:str,strategy_names:str) -> pd.DataFrame:\n",
    "#     \n",
    "#     stock_cum_sum = df_all_clean_after_merge.set_index([\"date\"]).groupby([\"sku\", \"store\"]).apply(\n",
    "#         lambda x: np.round((x[f\"stock_palmers\"].cumsum()-x[f\"stock_{strategy_names}\"].cumsum())/x[f\"stock_palmers\"].cumsum(),2)\n",
    "#     ).to_frame(\"stock_saving_cumsum_vs_palmers\").reset_index().fillna(0)\n",
    "#     stock_cum_sum[\"stock_saving_cumsum_vs_palmers\"] = np.where(stock_cum_sum[\"stock_saving_cumsum_vs_palmers\"]== -np.inf, 0, stock_cum_sum[\"stock_saving_cumsum_vs_palmers\"])\n",
    "#     df_all_clean_after_merge = df_all_clean_after_merge.merge(stock_cum_sum, on=[\"sku\", \"store\", \"date\"], how=\"left\")\n",
    "#     return df_all_clean_after_merge"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b98cd3e8bbe6242",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def find_last_sale_dates_global(dict_sales:dict) -> dict:\n",
    "#     last_sale_dates = {}\n",
    "#     for store, sales_data in dict_sales.items():\n",
    "#         for date, sales in sales_data.items():\n",
    "#             for sku, _ in sales:\n",
    "#                 if sku not in last_sale_dates or date > last_sale_dates[sku] and _ > 0:\n",
    "#                     last_sale_dates[sku] = date\n",
    "#     return last_sale_dates\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdff27bbc970cb2a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def find_first_sale_dates_global(dict_sales:dict) -> dict:\n",
    "#     first_sale_dates = {}\n",
    "#     for store, sales_data in dict_sales.items():\n",
    "#         for date, sales in sales_data.items():\n",
    "#             for sku, _ in sales:\n",
    "#                 if sku not in first_sale_dates or date < first_sale_dates[sku] and _ > 0:\n",
    "#                     first_sale_dates[sku] = date\n",
    "#     return first_sale_dates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db3188719ec0c329",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# develop AVG models strategy\n",
    "* delay parameter up to 7 days\n",
    "* window size up to a month\n",
    "* strategy is to compute the window size AVG up to delay ceil +1\n",
    "* opt means to try all range per id and save the best params"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4858fc3e4681b8fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e5c411f55ec2b77"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
